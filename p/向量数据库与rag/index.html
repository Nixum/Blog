<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='简单介绍向量数据库以及在RAG中的应用，附带小demo'><title>向量数据库与RAG</title>

<link rel='canonical' href='http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8Erag/'>

<link rel="stylesheet" href="/scss/style.min.92530ae6146419b2553c7da1866a1ac352d4c1a4d2f985110524bd60c6094d8c.css"><meta property='og:title' content='向量数据库与RAG'>
<meta property='og:description' content='简单介绍向量数据库以及在RAG中的应用，附带小demo'>
<meta property='og:url' content='http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8Erag/'>
<meta property='og:site_name' content='Nixum Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='向量数据库' /><meta property='article:tag' content='RAG' /><meta property='article:tag' content='AI' /><meta property='article:published_time' content='2024-06-22T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2024-06-22T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="向量数据库与RAG">
<meta name="twitter:description" content="简单介绍向量数据库以及在RAG中的应用，附带小demo">
    <link rel="shortcut icon" href="/img/favicon.ico" />

<script async src="https://www.googletagmanager.com/gtag/js?id=G-2D1N64V8VB"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-2D1N64V8VB', { 'anonymize_ip': false });
}
</script>

    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>









        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" >
                向量数据库
            </a>
        
            <a href="/categories/rag/" >
                RAG
            </a>
        
            <a href="/categories/ai/" >
                AI
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8Erag/">向量数据库与RAG</a>
    </h2>

    
    <h3 class="article-subtitle">
        简单介绍向量数据库以及在RAG中的应用，附带小demo
    </h3>
    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jun 22, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    3 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <p>[TOC]</p>
<h2 id="一从场景出发">一、从场景出发</h2>
<p>虽然目前ChatGPT等大语言模型已经十分好用了，无论是响应速度和回答的质量，基本上能解决我们日常一些问题和简单的工作，但不可否认，目前的大语言模型仍然有很多缺陷，比如：</p>
<ul>
<li>回答幻觉：大语言模型回答问题的本质上是基于其已有的训练数据，<strong>预测</strong>(推理)出哪些可能的文字作为答案，所以难免会出现张冠李戴、胡说八道的情况，最典型的比如你在 ChatGPT-3.5问他”西红柿炒钢丝球要怎么做“，它会十分正经的回答，又或者问一些代码问题，它有时也会回答出一些不存在的语法或者方法的调用，产生不正确的答案；</li>
<li>上下文限制：比如Chat GPT-3.5 Turbo的上下文限制是4K tokens（大概3000字），GPT-4 Turbo的上下文限制是128K tokens（大概9.6万字），这意味着其最多只能处理（记忆）这么多字的内容，且随着处理的上下文越多，响应速度也会越来越慢，成本越来越高；</li>
<li>训练的语料更新不够及时：比如Chat GPT-3.5 Turbo训练的语料库只记录了2021年9月之前的数据，GPT-4 Turbo则是2023年4月，这意味着在此之后产生的数据模型是不知道的；</li>
<li>在某些领域还不够专业：比如某些垂直领域的训练语料往往比较封闭，不对外公开，GPT训练的语料不够丰富准确，进而回答的质量就会大打折扣；</li>
</ul>
<p>为了优化上述问题，提升大语言模型回答的质量，其中一种解决方案就是在提问时向大语言模型提供更加准确且核心的资料供其参考，这个时候向量数据库就派上用场了。</p>
<h2 id="二向量数据库的作用">二、向量数据库的作用</h2>
<p>向量数据库并不是什么特别新的技术，早在机器学习场景中就有广泛应用，比如人脸识别、以图搜图、音乐软件的听音识曲等都有应用到，只是最近被大模型带火了一把。</p>
<blockquote>
<p>向量数据库用专门的数据结构和算法来处理向量之间的相似性计算和查询。 通过构建索引结构，向量数据库可以快速找到最相似的向量，以满足各种应用场景中的查询需求。</p>
</blockquote>
<p>上面是AWS上找到的对向量数据库的描述，以此代入到提升大模型回答质量的场景下，向量数据库的核心作用，就是将用户准备好的强相关性的<strong>文本转成向量，存储到数据库中</strong>，当用户输入问题时，也将问题转成向量，然后在数据库中进行<strong>相似性搜索</strong>，找到相关联的向量和上下文，进而找到对应的文本，最后跟着问题一起发送给大语言模型，从而达到减少模型的计算量，提升理解能力和响应速度，降低成本，绕过tokens限制，提高回答质量的目的，这种方式也被称为RAG（Retrieval Augmented Generation）检索增强生成。</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-flow.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-flow.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h2 id="三与传统数据库功能上的差异">三、与传统数据库功能上的差异</h2>
<p>或许你可能会疑惑，如果用传统数据库或者es等搜索出关联的信息，再跟着问题一起发送给大语言模型，也能实现类似的效果，这样行不行？答案当然是可以，但它不是最优的，出来的效果也并不好，原因在于传统数据库的搜索功能都是基于关键字搜索，只能匹配出对应的文本，语义上的联系其实非常弱。</p>
<p>传统数据库都是基于B+树或者分词+倒排索引的方式进行关键字匹配和排序，得到最终结果，例如，通过传统数据库搜索”布偶猫“，只能匹配得到带有”布偶猫“这个关键字相关的结果，无法得到”银渐层“、”蓝猫“等结果，因为他们是不同的词，传统数据库无法识别他们的语义关系。</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%bb%b4%e5%ba%a61.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%bb%b4%e5%ba%a61.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p>而向量数据库是基于向量搜索的，需要我们事先将”蓝猫“，”银渐层“，”布偶“，根据他们的特征比如大小、毛发长短、颜色、习性、脸型等维度，计算出一组数字后作为他们的代表进行存储（这组数字也被称为向量），只要分解的维度足够多，就能将所有猫区分出来，然后通过计算向量间的距离来判断他们的相似度，产生语义上的联系；</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%bb%b4%e5%ba%a62.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%bb%b4%e5%ba%a62.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h2 id="四向量数据库的核心要点">四、向量数据库的核心要点</h2>
<ul>
<li>将事物根据特征转换为不同维度的向量的过程，就叫做<strong>vector embedding向量嵌入：</strong></li>
<li>通过计算多个向量之间的距离来判断它们的相似度，就叫做<strong>similarity search相似性搜索；</strong></li>
</ul>
<p>这两个步骤，都决定着搜索质量的好坏。</p>
<h3 id="41-向量嵌入">4.1 向量嵌入</h3>
<p>以大语言模型对话的场景来说，涉及的语料就是大量的文本了，而文本包含的特征可以是词汇、语法、语义、情感、情绪、主题、上下文等等，这些特征太多了，可能需要几百上千个特征才能区分出一段文本表达的含义，很难进行人为的标注，因此需要有一种自动化的方式来提取这些特征，这就可以通过 vector embedding来实现。</p>
<p>这一步其实并不属于向量数据库的功能，更像是数据入库前的前置操作，向量数据库本事只提供存储向量和搜索的功能。</p>
<p>现在常用的大语言模型，基本都提供了embedding接口，供用户把文本转换为向量，比如 OpenAI的text-embedding-ada-002模型可以把文本分解成1536维的向量，网易的bce-embedding-base_v1模型，可以把文本分解为768维的向量等等，具体排名可以参考<a class="link" href="https://huggingface.co/spaces/mteb/leaderboard"  target="_blank" rel="noopener"
    >HuggingFace的大文本嵌入排行</a>，多少维其实就是一个长度多少的浮点类型数组，数组内的每个元素，则代表被分解的文本的特征，共同组成一个信息密集的表示。</p>
<p>那对于给定的文本，要如何分割，以及分解出多少个向量合适呢？</p>
<p>如果文本分割的粒度把控不好，可能会导致分割出来的无用信息太多，或者语义丢失，语义关联性不大等问题。对于文本分割，这里找到了一篇写得很好的文章：<a class="link" href="https://baoyu.io/translations/rag/5-levels-of-text-splitting"  target="_blank" rel="noopener"
    >文本分割的五个层次</a>：</p>
<ul>
<li>第 1 层：字符分割，比如按一定的字符数、块大小分割文本，不考虑其内容和形式。</li>
<li>第 2 层：基于分隔符分割，比如按句号、换行符、空格等进行文本切割。</li>
<li>第 3 层：文档类型分割，比如PDF、Markdown都有特定的语法表示语义分割，使得分割出来的文本关联性更强。</li>
<li>第 4 层：语义分割，比如每三句话转成向量，然后去掉第一句，加上下一句，再转成向量，比较两个向量的距离，如果距离超过一定的阈值，说明找到分割点。</li>
<li>第 5 层：使用大语言模型分割，使用适合的prompt指导大语言模型推理分割。</li>
</ul>
<p>简单来说，我们更倾向于把上下文关联性强的文本合一起分割，得到的整体效果最好，下面的demo，就是按第4层的分割方式，可以参考一下。</p>
<h3 id="42-相似性搜索">4.2 相似性搜索</h3>
<p>具体可以看这个<a class="link" href="https://www.bilibili.com/video/BV11a4y1c7SW"  target="_blank" rel="noopener"
    >视频</a>，有上下两集，讲得非常容易理解，这里仅作简单归纳。</p>
<p>现在我们已经将文本转换为向量存储在向量数据库中，如果想要在海量的数据里找到某个相似的向量，计算量会非常大，因此需要一种高效的算法来解决这个问题，类比到传统数据库，就是通过B+树建立索引进行查找，本质都是减少查询范围，从而快速找到结果。</p>
<p>在向量数据库中有两种主要的搜索方式：</p>
<ol>
<li>减少向量大小，对向量降维；</li>
<li>减少搜索范围，通过聚类或者将向量组织成树形、图形结构实现，限制搜索范围只在特定的聚类中过滤；</li>
</ol>
<p>这里简单介绍几种算法：</p>
<ul>
<li>K-Means：</li>
</ul>
<p>在保存向量数据后，对向量数据先进行聚类（比如随机选择某几个点），然后将这几个点最近的向量分配到这个聚类中，然后不断调整聚类的质心，形成不同的簇，这样，每次搜索时，只要先判断要搜索的向量属于哪个簇，然后再在簇中进行搜索，从而减少搜索范围。如果要搜索的向量刚好处在两个聚类的边界上，则只能动态调整搜索范围，搜索其他簇</p>
<p>如下图，在一个二维坐标系中划定4个聚类中心，形成4个簇；</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%b0%87.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%b0%87.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<ul>
<li>积量化Product Quantization，PQ：</li>
</ul>
<p>随着数据规模的增大和维度的增加，数据点间的距离也会呈指数级增长，聚类算法需要分割更多的聚类（否则会导致向量和自己聚类的中心距离太远，降低搜索速度和质量），而且消耗的内存也会增加，解决这个问题的方法是将向量分解为多个子向量，然后再对每个子向量独立进行量化（量化的意思就是通过质心进行编号形成码本，在此聚类中的向量都对应这个编号，从而不用存储完整向量），从而实现降维，但代价就是搜索的质量会下降。</p>
<p>如下图，在一个二维的坐标系中的四个聚类，每个聚类中的向量都用质心向量来替代表示，这样就只剩下4个向量了，然后只要维护好这4个向量形成的码本，就能极大的降低内存开销。(码本的作用是记录原始向量对质心的映射，有点类似操作系统中的内存多级分页算法)</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e8%81%9a%e7%b1%bb1.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e8%81%9a%e7%b1%bb1.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e8%81%9a%e7%b1%bb2.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e8%81%9a%e7%b1%bb2.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p>当向量的维度越高，向量分布越稀疏，形成的聚类也就越多，单纯根据质心构建码本的方式会导致码本的存储开销越来越大，比如一个128维的向量空间，如果直接按聚类分需要分为2^64个质心才能保证搜索质量，此时的质心编码和向量值的码本的内存消耗将巨大，甚至大于量化本身所节省下来的内存；</p>
<p>此时就需要降维，将128维的向量分成8个16维的子向量，再对8个16维的子空间中进行k-means聚类训练，从而降低聚类的数量，此时一个向量被量化为8个编码值，同时每个子空间也会构建自己的子码本（此时只需要保存这8个子码本即可），使用时用8个编码值分别从对应的子码本中查询出8个16维的子向量再拼起来复原出一个128维的向量。</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e9%99%8d%e7%bb%b41.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e9%99%8d%e7%bb%b41.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e9%99%8d%e7%bb%b42.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e9%99%8d%e7%bb%b42.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<ul>
<li>局部敏感哈希Locality Sensitive Hashing，LSH</li>
</ul>
<p>可以理解为反向哈希，以往我们都期望往哈希表里添加数据，都期望减少哈希碰撞的次数，即桶上的数据越少越好，这样方便我们快速找到对应的value，但是在向量搜索中，因为是为了找到相似的向量，所以我们期望哈希碰撞的次数尽可能的高，这样相似的向量都会落在一个桶上。</p>
<p>这些算法本身就在查询速度、查询质量、内存开销上进行取舍，做出一个权衡。</p>
<h3 id="43-相似性度量">4.3 相似性度量</h3>
<p>判断两个向量是否相似，其实就是计算出两个向量间的距离，根据距离来判断他们的相似度，常见的有三种相似度算法：</p>
<ul>
<li>欧几里得距离：</li>
</ul>
<p>欧几里得距离是指两个向量之间的距离，它的计算公式为：𝑑(𝐴,𝐵)=∑𝑖=1𝑛(𝐴𝑖−𝐵𝑖)2<em>d</em>(<strong>A</strong>,<strong>B</strong>)=<em>i</em>=1∑<em>n</em>(<em>Ai</em>−<em>Bi</em>)2</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e6%ac%a7%e5%87%a0%e9%87%8c%e5%be%97.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e6%ac%a7%e5%87%a0%e9%87%8c%e5%be%97.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<ul>
<li>余弦相似度：</li>
</ul>
<p>余弦相似度是指两个向量之间的夹角余弦值，它的计算公式为：cos⁡(𝜃)=𝐴⋅𝐵∣𝐴∣∣𝐵∣cos(<em>θ</em>)=∣A∣∣B∣A⋅B</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e4%bd%99%e5%bc%a6.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e4%bd%99%e5%bc%a6.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<ul>
<li>点积相似度：</li>
</ul>
<p>向量的点积相似度是指两个向量之间的点积值，它的计算公式为：𝐴⋅𝐵=∑𝑖=1𝑛𝐴𝑖𝐵𝑖<strong>A</strong>⋅<strong>B</strong>=<em>i</em>=1∑<em>nAiBi</em></p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%82%b9%e7%a7%af.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-%e7%82%b9%e7%a7%af.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<p>都是纯数学的直接代入公式即可得出结果，计算出一个数值，然后跟我们设定的相似度阈值做比较，小于该阈值说明非常相似，大于阈值说明不相似。</p>
<h3 id="44-过滤">4.4 过滤</h3>
<p>向量数据库也具备传统数据库那种可以根据部分业务字段进行过滤，之后再进行相似性查询，这些字段构成的就称为元数据，所以向量数据库通常需要维护两个索引，一个是向量索引，另一个是元数据索引，两者相结合从而快速找到需要的数据。</p>
<h2 id="五常见的向量数据库">五、常见的向量数据库</h2>
<table>
<thead>
<tr>
<th>DB</th>
<th>是否开源</th>
<th>功能简述</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="link" href="https://github.com/chroma-core/chroma"  target="_blank" rel="noopener"
    >Chroma</a></td>
<td>是</td>
<td>简单：类型完整、测试全面、文档完整整合：支持LangChain（python和js）、LlamaIndex等等</td>
</tr>
<tr>
<td><a class="link" href="https://www.pinecone.io/"  target="_blank" rel="noopener"
    >Pinecone</a></td>
<td>否</td>
<td>相似性搜索、推荐系统、个性化和语义搜索免费版可以支持500w的向量存储，其用法简单，价格低廉，可以快速支持向量检索业务的验证与尝试。</td>
</tr>
<tr>
<td><a class="link" href="https://github.com/weaviate/weaviate"  target="_blank" rel="noopener"
    >Weaviate</a></td>
<td>是</td>
<td>向量搜索，语义搜索、推荐系统可以存储对象、向量，支持将矢量搜索与结构化过滤与云原生数据库容错和可拓展性等能力相结合。 支持GraphQL、REST和各种语言的客户端访问</td>
</tr>
<tr>
<td><a class="link" href="https://github.com/milvus-io/milvus"  target="_blank" rel="noopener"
    >Milvus</a></td>
<td>是，云原生版本为zilliz</td>
<td>对包含数百万、数十亿甚至数万亿个向量的密集向量数据集进行相似性搜索；支持万亿向量数据集上的毫秒级搜索：在万亿向量数据集上测试平均延迟（毫秒级）云原生版本有免费额度，不过只支持创建两个collection</td>
</tr>
<tr>
<td><a class="link" href="https://github.com/facebookresearch/faiss"  target="_blank" rel="noopener"
    >Faiss</a></td>
<td>是</td>
<td>图像识别、语义搜索Facebook背书</td>
</tr>
<tr>
<td><a class="link" href="https://github.com/spotify/annoy"  target="_blank" rel="noopener"
    >Annoy</a></td>
<td>是</td>
<td>Spotify背书，基于随机投影和树的算法，支持多种相似算法低维度效果会更好（比如&lt;=100），但即使是1000维的维度，它的表现也还是非常优秀</td>
</tr>
<tr>
<td><a class="link" href="https://github.com/elastic/elasticsearch"  target="_blank" rel="noopener"
    >Elasticsearch  8.0 以上版本</a></td>
<td>是</td>
<td>实现文本的语义搜索或者图像、视频或音频的相似度搜索提供了基础</td>
</tr>
<tr>
<td><a class="link" href="https://supabase.com/blog/openai-embeddings-postgres-vector"  target="_blank" rel="noopener"
    >PostgreSQL + pgvector插件</a></td>
<td>是</td>
<td>支持精确和近似最近搜索（ANN)，提供三种距离即使方法：欧几里得距离、余弦距离、内积</td>
</tr>
</tbody>
</table>
<h2 id="六rag-demo">六、RAG demo</h2>
<p>强烈建议可以看<a class="link" href="https://python.langchain.com/v0.2/docs/introduction/"  target="_blank" rel="noopener"
    >langchain的官方文档</a>，写得非常详细且清晰，demo也很容易跑起来，而且也可以在他们的官方文档上体验一下相似性搜索。</p>
<p>这里也基于langchain框架，使用chroma作为向量数据库，使用ollama管理的本地大模型llama2-chinese（也用它作为vector embedding），文本预处理使用<a class="link" href="https://baoyu.io/translations/rag/5-levels-of-text-splitting"  target="_blank" rel="noopener"
    >文本分割的五个层次</a>提到的第四场的方法，然后按照下面的流程，实现一个简单的RAG demo。</p>
<p>只是一个小demo，体验一下RAG的流程而已，出来的效果不一定很好哈。</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rag-flow.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rag-flow.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<ul>
<li>安装ollama作为本地LLM，跟着它<a class="link" href="https://github.com/ollama/ollama"  target="_blank" rel="noopener"
    >github</a>上的步骤进行安装即可，我测试的时候是用docker进行安装的，然后指定它跑在GPU上，不然推理答案的速度太慢了；</li>
<li>准备一篇markdown文章，就可以开始写代码了，这里把整个流程分割成多个步骤，每个步骤可以独立运行；</li>
</ul>
<ol>
<li>将markdown文章进行预处理，分割成文本块：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">Ollama</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredMarkdownLoader</span>
<span class="kn">from</span> <span class="nn">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_community.embeddings</span> <span class="kn">import</span> <span class="n">OllamaEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_retrieval_chain</span>
<span class="kn">from</span> <span class="nn">langchain.chains.combine_documents</span> <span class="kn">import</span> <span class="n">create_stuff_documents_chain</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">codecs</span>

<span class="c1"># 解析 md 内容，并llama2-chinese作为嵌入模型计算向量，然后转成 json 文件</span>

<span class="n">markdown_path</span> <span class="o">=</span> <span class="s2">&#34;markdown文章的路径&#34;</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">UnstructuredMarkdownLoader</span><span class="p">(</span><span class="n">markdown_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;elements&#34;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;llama2-chinese&#34;</span><span class="p">)</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
        <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;sentence&#39;</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">page_content</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                <span class="s1">&#39;vectors&#39;</span><span class="p">:</span> <span class="n">vectors</span>
        <span class="p">})</span>
        <span class="c1"># 打印内容及其转换的向量</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">page_content</span> <span class="o">+</span> <span class="s2">&#34;  &#34;</span> <span class="o">+</span> <span class="n">vectors</span> <span class="o">+</span> <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

<span class="c1"># 将转换结果写入json文件中</span>
<span class="n">sentencesJson</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">with</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;sentences.json&#39;</span><span class="p">,</span><span class="s2">&#34;w&#34;</span><span class="p">,</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">sentencesJson</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>将上一步得到的文本 + 嵌入的向量，存入到 chroma DB中：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">Ollama</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredMarkdownLoader</span>
<span class="kn">from</span> <span class="nn">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_community.embeddings</span> <span class="kn">import</span> <span class="n">OllamaEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_retrieval_chain</span>
<span class="kn">from</span> <span class="nn">langchain.chains.combine_documents</span> <span class="kn">import</span> <span class="n">create_stuff_documents_chain</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">import</span> <span class="nn">chromadb</span>

<span class="c1"># 加载上一步拆分出来的文本及其向量值</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;sentences.json&#34;</span><span class="p">,</span> <span class="s2">&#34;rb&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># 构建一个chroma db实例</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">chromadb</span><span class="o">.</span><span class="n">PersistentClient</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&#34;./chroma_db&#34;</span><span class="p">)</span>
<span class="c1"># 获取要存储的collection</span>
<span class="n">collection</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_or_create_collection</span><span class="p">(</span><span class="s2">&#34;demo&#34;</span><span class="p">)</span>
<span class="c1"># 构建要保存的内容</span>
<span class="n">embeddingList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">docList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
        <span class="n">embeddingList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&#34;vectors&#34;</span><span class="p">])</span>
        <span class="n">docList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&#34;sentence&#34;</span><span class="p">])</span>
        <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&#34;1-&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&#34;index&#34;</span><span class="p">]))</span>
<span class="c1"># 保存到chroma中</span>
<span class="n">collection</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddingList</span><span class="p">,</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">docList</span><span class="p">,</span>
    <span class="n">ids</span><span class="o">=</span><span class="n">ids</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>向 ollama 提问，此时会先基于问题，使用llama2-chinese嵌入模型转换为向量，在chroma 中进行相似性搜索，查找出对应的文本，然后将检索得到的文本 + 问题，一起发给ollama，由ollama的llama2-chinese模型推理给出答案；</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">Ollama</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredMarkdownLoader</span>
<span class="kn">from</span> <span class="nn">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_community.embeddings</span> <span class="kn">import</span> <span class="n">OllamaEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_retrieval_chain</span>
<span class="kn">from</span> <span class="nn">langchain.chains.combine_documents</span> <span class="kn">import</span> <span class="n">create_stuff_documents_chain</span>

<span class="c1"># 加载嵌入模型，将问题转换成向量，这一步只是为了打印相似性搜索的结果</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;llama2-chinese&#34;</span><span class="p">)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">persist_directory</span><span class="o">=</span><span class="s2">&#34;./chroma_db&#34;</span><span class="p">,</span>
        <span class="n">collection_name</span><span class="o">=</span><span class="s2">&#34;demo&#34;</span><span class="p">,</span>
        <span class="n">embedding_function</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;这里改成想要问的问题&#34;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;根据问题从db中相似性搜索出来的文本：&#34;</span> <span class="o">+</span> <span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>

<span class="c1"># ----------------------------------------------------------</span>
<span class="c1"># 加载LLM模型</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">Ollama</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;llama2-chinese&#34;</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&#34;&#34;&#34;仅依据下面提供的上下文，回答我接下来的问题:
</span><span class="s2">&lt;context&gt;
</span><span class="s2"></span><span class="si">{context}</span><span class="s2">
</span><span class="s2">&lt;/context&gt;
</span><span class="s2">问题: </span><span class="si">{input}</span><span class="s2">&#34;&#34;&#34;</span><span class="p">)</span>

<span class="c1"># 这里langchain已经帮我们整合了 “根据问题从db中相似性搜索出来的答案” 这个步骤了</span>
<span class="n">document_chain</span> <span class="o">=</span> <span class="n">create_stuff_documents_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>
<span class="n">retrieval_chain</span> <span class="o">=</span> <span class="n">create_retrieval_chain</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">document_chain</span><span class="p">)</span>
<span class="c1"># 发送问题+相关联的文本，从而实现检索增强，即RAG</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">retrieval_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&#34;input&#34;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s2">&#34;answer&#34;</span><span class="p">])</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="七其他参考">七、其他参考</h2>
<p><a class="link" href="https://www.bilibili.com/video/BV1JF4m177Wd"  target="_blank" rel="noopener"
    >RAG + 向量数据库科普</a></p>
<p><a class="link" href="https://juejin.cn/post/7250794190120353847"  target="_blank" rel="noopener"
    >基于langchain 的文档问答 最佳实践</a></p>
<p><a class="link" href="https://cloud.tencent.com/developer/article/2311302"  target="_blank" rel="noopener"
    >用GPT-4和ChromaDB与文本文件对话教程</a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/651179780"  target="_blank" rel="noopener"
    >基于LLM+向量库的文档对话痛点及解决方案</a></p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/641132245"  target="_blank" rel="noopener"
    >LLM+Embedding构建问答系统的局限性及优化方案</a></p>
<p><a class="link" href="https://python.langchain.com/v0.2/docs/how_to/markdown_header_metadata_splitter/"  target="_blank" rel="noopener"
    >langchain - How to split Markdown by Headers</a></p>
<p><a class="link" href="https://aitutor.liduos.com/02-langchain/02-1.html"  target="_blank" rel="noopener"
    >langchain入门</a></p>
<p><a class="link" href="https://www.wehelpwin.com/article/4387"  target="_blank" rel="noopener"
    >chatgpt原理1</a></p>
<p><a class="link" href="https://brightliao.com/2023/04/25/chatgpt-a-technical-summary/"  target="_blank" rel="noopener"
    >chatgpt原理2</a></p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/">向量数据库</a>
        
            <a href="/tags/rag/">RAG</a>
        
            <a href="/tags/ai/">AI</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    <aside class="related-contents--wrapper">
    
    
</aside>

     
    
        
    <script src="https://utteranc.es/client.js" 
        repo="Nixum/blog"
        issue-term="pathname"
        
        crossorigin="anonymous"
        async
        >
</script>

<style>
    .utterances {
        max-width: unset;
    }
</style>

<script>
    function setUtterancesTheme(theme) {
        let utterances = document.querySelector('.utterances iframe');
        if (utterances) {
            utterances.contentWindow.postMessage(
                {
                    type: 'set-theme',
                    theme: `github-${theme}`
                },
                'https://utteranc.es'
            );
        }
    }

    addEventListener('message', event => {
        if (event.origin !== 'https://utteranc.es') return;
        setUtterancesTheme(document.documentElement.dataset.scheme)
    });

    window.addEventListener('onColorSchemeChange', (e) => {
        setUtterancesTheme(e.detail)
    })
</script>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 Nixum Blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.6.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">

            <section class="widget archives">
                <form action="/search/" class="search-form widget" >
        <p>
            <label>Search</label>
            <input name="keyword" required placeholder="Type something..." />
        
            <button title="Search">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



            </button>
        </p>
    </form>
            </section>

            <section class="widget archives">
                <h2 class="widget-title section-title">Contents</h2>

                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li>
      <ol>
        <li><a href="#一从场景出发">一、从场景出发</a></li>
        <li><a href="#二向量数据库的作用">二、向量数据库的作用</a></li>
        <li><a href="#三与传统数据库功能上的差异">三、与传统数据库功能上的差异</a></li>
        <li><a href="#四向量数据库的核心要点">四、向量数据库的核心要点</a>
          <ol>
            <li><a href="#41-向量嵌入">4.1 向量嵌入</a></li>
            <li><a href="#42-相似性搜索">4.2 相似性搜索</a></li>
            <li><a href="#43-相似性度量">4.3 相似性度量</a></li>
            <li><a href="#44-过滤">4.4 过滤</a></li>
          </ol>
        </li>
        <li><a href="#五常见的向量数据库">五、常见的向量数据库</a></li>
        <li><a href="#六rag-demo">六、RAG demo</a></li>
        <li><a href="#七其他参考">七、其他参考</a></li>
      </ol>
    </li>
  </ol>
</nav>
                </div>
            </section>

            <section class="widget archives">
                <h2 class="widget-title section-title">Other Article Tags</h2>
                <section class="widget tagCloud">
    <div class="tagCloud-tags">
        
            <a href="/tags/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/" class="font_size_3">
                主从架构
            </a>
        
            <a href="/tags/javase/" class="font_size_2">
                JavaSE
            </a>
        
            <a href="/tags/%E6%80%BB%E7%BB%93/" class="font_size_2">
                总结
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="font_size_2">
                数据库
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%94%81/" class="font_size_2">
                数据库-锁
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/" class="font_size_2">
                数据库事务
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/" class="font_size_2">
                数据库优化
            </a>
        
            <a href="/tags/%E7%B4%A2%E5%BC%95/" class="font_size_2">
                索引
            </a>
        
            <a href="/tags/ai/" class="font_size_1">
                AI
            </a>
        
            <a href="/tags/context%E5%8E%9F%E7%90%86/" class="font_size_1">
                context原理
            </a>
        
            <a href="/tags/docker/" class="font_size_1">
                docker
            </a>
        
            <a href="/tags/etcd/" class="font_size_1">
                etcd
            </a>
        
            <a href="/tags/git/" class="font_size_1">
                git
            </a>
        
            <a href="/tags/go/" class="font_size_1">
                Go
            </a>
        
            <a href="/tags/go-channel%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go channel原理
            </a>
        
            <a href="/tags/go-gc/" class="font_size_1">
                Go GC
            </a>
        
            <a href="/tags/go-gin%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go Gin原理
            </a>
        
            <a href="/tags/go-slice%E5%92%8Cmap%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go slice和map原理
            </a>
        
            <a href="/tags/go-sync%E5%8C%85/" class="font_size_1">
                Go sync包
            </a>
        
            <a href="/tags/goroutine/" class="font_size_1">
                Goroutine
            </a>
        
            <a href="/tags/go%E5%B9%B6%E5%8F%91/" class="font_size_1">
                Go并发
            </a>
        
            <a href="/tags/http/" class="font_size_1">
                HTTP
            </a>
        
            <a href="/tags/ioc%E5%92%8Caop/" class="font_size_1">
                IOC和AOP
            </a>
        
            <a href="/tags/istio/" class="font_size_1">
                Istio
            </a>
        
            <a href="/tags/java-bio/" class="font_size_1">
                Java BIO
            </a>
        
            <a href="/tags/java-gc/" class="font_size_1">
                Java GC
            </a>
        
            <a href="/tags/java-nio/" class="font_size_1">
                Java NIO
            </a>
        
            <a href="/tags/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/" class="font_size_1">
                Java内存模型
            </a>
        
            <a href="/tags/java%E5%B9%B6%E5%8F%91/" class="font_size_1">
                Java并发
            </a>
        
            <a href="/tags/java%E9%9B%86%E5%90%88%E7%B1%BB%E5%8E%9F%E7%90%86/" class="font_size_1">
                Java集合类原理
            </a>
        
            <a href="/tags/juc/" class="font_size_1">
                JUC
            </a>
        
            <a href="/tags/jvm/" class="font_size_1">
                JVM
            </a>
        
            <a href="/tags/jwt/" class="font_size_1">
                JWT
            </a>
        
            <a href="/tags/kubernetes/" class="font_size_1">
                Kubernetes
            </a>
        
            <a href="/tags/linux/" class="font_size_1">
                Linux
            </a>
        
            <a href="/tags/mongodb/" class="font_size_1">
                MongoDB
            </a>
        
            <a href="/tags/mysql/" class="font_size_1">
                MySQL
            </a>
        
            <a href="/tags/netty/" class="font_size_1">
                Netty
            </a>
        
            <a href="/tags/orm/" class="font_size_1">
                ORM
            </a>
        
            <a href="/tags/rag/" class="font_size_1">
                RAG
            </a>
        
            <a href="/tags/redis/" class="font_size_1">
                Redis
            </a>
        
            <a href="/tags/rpc/" class="font_size_1">
                RPC
            </a>
        
            <a href="/tags/select%E5%8E%9F%E7%90%86/" class="font_size_1">
                select原理
            </a>
        
            <a href="/tags/session%E5%92%8Ccookie/" class="font_size_1">
                session和cookie
            </a>
        
            <a href="/tags/socket/" class="font_size_1">
                socket
            </a>
        
            <a href="/tags/spring/" class="font_size_1">
                Spring
            </a>
        
            <a href="/tags/spring-security/" class="font_size_1">
                Spring Security
            </a>
        
            <a href="/tags/springboot/" class="font_size_1">
                SpringBoot
            </a>
        
            <a href="/tags/springmvc/" class="font_size_1">
                SpringMVC
            </a>
        
            <a href="/tags/tcp/" class="font_size_1">
                TCP
            </a>
        
    </div>
</section>
            </section>

        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>


    </body>
</html>
