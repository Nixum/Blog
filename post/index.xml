<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nixum Blog</title>
    <link>http://nixum.cc/post/</link>
    <description>Recent content in Posts on Nixum Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="http://nixum.cc/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MongoDB</title>
      <link>http://nixum.cc/p/mongodb/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mongodb/</guid>
      <description>[TOC]
特点  分布式数据库，Json数据模型，面向对象数据模型，不强制表的scheme 当应用场景不清晰时，可以直接以对象模型直接存储，无需关心字段，表结构灵活，动态增加新字段 不用太过关注表间的关系，可直接嵌套存储，将多种关系存储在同一张表上，同时也加快查表，因为它可以减少磁盘定位次数，如果是关系型数据库，同时查多张表就需要定位多次 原生支持高可用，一般的部署方式是部署三个节点replica set，最多50个；多replica set可以实现自恢复（当主节点挂点后会选出从节点），异地容灾，数据库滚动更新 原生支持横向扩展，通过水平扩展分片实现，外部并不感知有多少个分片，只会当成一个分片使用 支持字段级加密，针对隐私数据，比如身份证、电话等，在入库时可以进行加密，查询时解密 支持地理位置经纬度查询 强大的聚合查询，适合报表、时序数据  NoSQL语句 客户端使用驱动时连接的执行流程
 客户端执行流程 
数据库端执行流程
 数据库端执行流程 
要获取ticket是因为MongoDB默认存储引擎wiredtiger的机制，ticket代表着系统资源的数量，ticket数量有限，读写操作都需要先获得ticket才可以进行下一步操作，机制类似信号量。
连接 连接mongoDB语句，当有多节点或多分片时，连接也要写上，mongodb://节点1的host:port, 节点2的host:port,.../databaseName?[options: maxPoolSize(java默认是100), maxWaitTime(查询的最大等待事件), writeConcern, readConcern]
mongoDB驱动里已提供负载均衡，多节点探测
聚合 作用相当与group by，可作用与多个collection，可进行查询和计算。Mongo的聚合操作发生在pipeline中，由多个stage组成，有点像责任链，通过多个state来过滤，聚合数据，每一个{}代表一个state
demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  MySQL中的SELECTdepartment,count(null)asemp_QTYFROMUserWHEREgender=&amp;#39;female&amp;#39;GROUPBYdepartmentHAVINGcount(*)&amp;lt;10等价于mongo中的db.user.aggregate([{$match:{gender:&amp;#39;female&amp;#39;}},{$group:{_id:&amp;#39;$DEPARTMENT&amp;#39;,emp_qty:{$sum:1}}},{$match:{emp_qty:{$lt:10}}}])  几个比较特别的运算符
$unwind：将查询到的数组展开
$grouphLookup：图搜索
$facet/$bucket: 分面搜索，根据不同范围条件，多个维度一次性进行分组输出
文档模型设计原则   传统关系型数据库设计，从概念模型 -》逻辑模型 -》物理模型，关系明确，遵循三范式（1.要有主键，列不可分，2.每列与主键相关，3.不能存在传递依赖(不允许字段冗余)），表现形式上，一对多关系，外键在多那张表上，多对多关系，会有第三张表来做关联
对于文档模型，一般对应关系型数据库设计的逻辑模型阶段，通过嵌套实体数组，map或者引用字段来处理实体间的关系，字段冗余限制宽松</description>
    </item>
    
    <item>
      <title>容器</title>
      <link>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</guid>
      <description>[TOC]
底层原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个边界。
Namespace - 隔离 进程只能看到被规定的视图，即 隔离，比如通过docker启动一个/bin/sh，再在容器里通过ps命令查看该/bin/sh进程的pid，会发现它的pid是1，但是实际上它在外部的宿主机里的pid是10，使得让在容器里运行的进程以为自己就在一个独立的空间里，实际上只是进行了逻辑的划分，本质还是依赖宿主机。
作用：在同一台宿主机上运行多个用户的容器，充分利用系统资源；不同用户之间不能访问对方的资源，保证安全。
常见的Namespace类型有：
 PID Namespace：隔离不同容器的进程 Network Namespace：隔离不同容器间的网络 Mount Namespace：隔离不同容器间的文件系统  与虚拟化的区别：虚拟化是在操作系统和硬件上进行隔离，虚拟机上的应用需要经过虚拟机在经过宿主机，有两个内核，本身就有消耗，而容器化后的应用仅仅只是宿主机上的进程而已，只用到宿主机一个内核
因为namespace隔离的并不彻底，由于内核共享，容器化应用仍然可以把宿主机的所有资源都吃掉，有些资源不同通过namespace隔离，比如修改了容器上的时间，宿主机上的时间也会被改变，因此需要Cgroups
Cgroups - 资源限制 是用来制造约束的主要手段，即对进程设置资源能够使用的上限，如CPU、内存、IO设备的流量等
比如，限定容器只能使用宿主机20%的CPU
1  docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash    Cgroups 通过不同的子系统限制了不同的资源，每个子系统限制一种资源。每个子系统限制资源的方式都是类似的，就是把相关的一组进程分配到一个控制组里，然后通过树结构进行管理，每个控制组都设有自己的资源控制参数。
 常见的Cgroups子系统
 CPU 子系统，用来限制一个控制组（一组进程，你可以理解为一个容器里所有的进程）可使用的最大 CPU。 memory 子系统，用来限制一个控制组最大的内存使用量。 pids 子系统，用来限制一个控制组里最多可以运行多少个进程。 cpuset 子系统， 这个子系统来限制一个控制组里的进程可以在哪几个物理 CPU 上运行。  Cgroups 有 v1 和 v2 两个版本，v1中每个进程在各个Cgroups子系统中独立配置，可以属于不同的group，比较灵活但因为每个子系统都是独立的，会导致对同一进程的资源协调困难，比如同一容器配置了Memory Cgroup和Blkio Cgroup，但是它们间无法相互协作。
v2针对此做了改进，使各个子系统可以协调统一管理资源。
Mount Namespace与rootfs(根文件系统) 挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，即容器镜像，也是容器的根文件系统。Mount Namespace保证每个容器都有自己独立的文件目录结构。
镜像可以理解为是容器的文件系统（一个操作系统的所有文件和目录），它是只读的，挂载在宿主机的一个目录上。同一台机器上的所有容器，都共享宿主机操作系统的内核，如果容器内应用修改了内核参数，会影响到所有依赖的应用。而虚拟机则都是独立的内核和文件系统，共享宿主机的硬件资源。
 上面的读写层通常也称为容器层，下面的只读层称为镜像层，所有的增删查改操作都只会作用在容器层，相同的文件上层会覆盖掉下层。知道这一点，就不难理解镜像文件的修改，比如修改一个文件的时候，首先会从上到下查找有没有这个文件，找到，就复制到容器层中，修改，修改的结果就会作用到下层的文件，这种方式也被称为copy-on-write。</description>
    </item>
    
    <item>
      <title>微服务</title>
      <link>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>[TOC]
一些概念理解   微服务：http://dockone.io/article/3687
  中间件（Middleware）：是处于操作系统和应用程序之间的软件，用来屏蔽底层的技术细节，以自身的复杂性换来了应用程序开发的简单。广义中间件的定义是非常广泛的，比如消息、注册配置中心、网关、数据库访问、集成平台等等，都属于中间件的范畴。
  云原生：应用程序从设计之初即考虑到云的环境，原生为云而设计，在云上以最佳状态运行，充分利用和发挥云平台的弹性和分布式优势。代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API（如K8s），组合起来就算服务容器化，整体使用微服务架构，应用支持容器编排调度。
云原生的本质其实是基础设施与业务的解耦，以及基础设施自身的标准化。
  IaaS：基础结构即服务，基础设施，如AWS的EC2、S3等，只提供比较原始的硬件功能，用户不用买服务器，自己去构建网络，防火墙、硬盘存储等基础设施，即提供基础环境配备。剩下的由用户自己完成。
  PaaS：平台即服务，中间件、解决方案、工具和服务的集合，如AWS的DocDB、Redis、SQS、SNS等设施，让用户更专注自己业务逻辑的开发，对于使用的工具，拿来即用。
  FaaS：功能即服务，service less，如AWS的lambda，用户只需要写对应的业务方法就能提供对应的服务，其他都不用管
  SaaS：软件即服务，应用层面了，比如Shopify、moka，提供某一业务领域的解决方案，直接注册使用即可
  DevOps：一种模式，与敏捷挂钩，集文化理念、实践和工具于一身，快速迭代和部署，提供组织快速交付应用的能力。自动化部署、自动化运维，适合敏捷开发和快速迭代，解决传统开发和运维相互独立，沟通频繁，效率低等问题
  限流 下面的方案都是单机版本的，在分布式环境下可以把限流的实例放到Redis里，或者直接使用Lua脚本实现，保证并发安全。
固定窗口 规定单位时间内可访问的次数，比如规定接口一分钟内只能访问10次，以第一次请求为起始，计数1，一分钟内计数超过10后，后续的请求直接拒绝，只能等到这一分钟结束后，重置计数，重新开始计数。
但是这样有个问题，如果在大部分请求集中在第一个窗口的后10s内，和第二个窗口的前10s内，虽然他们都符合限流策略，但是在临界的20s内，请求还是有可能压垮系统。
算法Demo：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  type fixWinLimiter struct { lock *sync.</description>
    </item>
    
    <item>
      <title>常见的业务场景解决方案整理</title>
      <link>http://nixum.cc/p/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%95%B4%E7%90%86/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%95%B4%E7%90%86/</guid>
      <description>[TOC]
防止表单重复提交 场景：用户点击下单页面，跳转至下单页面，提交订单，此时有可能网络原因或者用户点击多次，导致订单重复提交。
解决：用户跳转至下单页前，会先获取订单号(也作为订单表主键)，将订单号绑定在下单页，利用数据库主键唯一的特性，让创建订单的操作变成幂等性。
解决ABA问题 **场景：**类似MySQL的丢失更新，比如有操作1，操作2先后对记录A进行更新，操作1的响应丢失导致重试，此时操作2已经更新成功，操作1重试时会覆盖操作2的更新。
**解决：**通过版本号解决，订单表增加一列作版本号，版本号可以使用递增序列、时间戳等，通过比较版本号来确定操作的先后顺序，更新成功时也需要更新版本号。
流量大、数据量大的商品详情页数据存储 **场景：**一般商品详情页都是访问量最大的页面，比如用户做商品对比、查看商品详情都需要，另外就是商品详情页一般涉及很多数据，如下，且后端存储的sku量也是巨大的，直接分多张表去存虽然可以实现，但是性能就一般了。
商品 ├── 基本信息 │ ├── 标题、副标题 │ ├── 价格：原价、促销价 │ └── 颜色、规格等 ├── 商品参数 ├── 商品介绍 ├── 图片视频 来自其他系统的 ├── 促销信息 ├── 推荐商品 ├── 评论、评价 ├── 配送信息 └── 店铺信息 **解决：**分析不同的数据特性，比如有些数据是热点的、相对固定的、不常被修改的、需求变化不大的等各种维度去划分，进行不同存储。动态数据、实时数据还是照旧，该怎么处理怎么处理，其他的可以：
  套一层缓存在数据库外面，查询数据先缓存后数据库
  针对每个不同的spu有不同的商品属性，则可以使用NoSQL来解决
  针对图片、视频等数据，使用对象存储、CDN解决，比如AWS S3，直接通过其提供的API进行访问，将这部分的压力转移到云服务厂商
  将相对固定的数据静态化，比如商品介绍，其包含了大量的文字、图片、视频等，可直接将这一部分保存成HTML文件中，访问时直接返回HTML文件，保存成HTML还可以配合CDN进行加速
  查询方面的优化  可以起一个SQL检查脚本，检查执行时间过长的SQL，如果超过指定时间的，进行记录和kill，再进行优化，把慢SQL解决掉，避免多个执行时间过长的SQL拖垮整个数据库。 主从分离，读写分离，服务降级 分析SQL执行和访问量间的关系，数据库CPU利用率变化 MySQL单次查询扫描的数据量控制在千万级别内，单次扫描的数据量在百万级别是可以接受，理论上查询都应该使用索引，避免全表扫描  对象存储原理  本质是一个规模很大的分布式Key-value集群，外加一个保存集群节点信息、文件信息和映射关系(统称为元数据)的节点集群，在最外层再加上一个Gateway来对外提供服务即可。 针对图片、视频等大文件，在存储时会将其拆分成多个大小相等的块Block，一般是几十KB到几MB，便于管理，也可以分散到不同节点，提升并行读写性能。 由于分成的块太小，数量多，一般也不是直接进行管理的，而是将一些块进行聚合，放到容器里，类似分片的概念，主从复制时，也是直接复制这些块即可，不用再复制多日志  跨系统数据实时同步  采用Bin Log + MQ的方式，将上游数据实时同步到下游其他系统的数据库中，为了确保数据一致性，必须顺序读取Bin Log，因此MQ的主题也必须设置为只有一个分区，才能保证Bin Log有序。 当下游系统想要扩展消费能力时，不可盲目增加同步线程数和MQ主题分区，由于Bin Log的顺序性，要确保多线程消费时，不会对数据产生影响，所以可以将具有因果一致性的Bin Log发布给同一主题分区，才可以多线程同步消费。具体可参考MySQL 5.</description>
    </item>
    
    <item>
      <title>Go Context和Channel</title>
      <link>http://nixum.cc/p/go-context%E5%92%8Cchannel/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-context%E5%92%8Cchannel/</guid>
      <description>[TOC]
Context 一个接口，包含如下方法，主要用于实现主协程对子协程的控制，作用包括取消执行、设置超时时间、携带键值对等
1 2 3 4 5 6 7 8 9 10  type Context interface { // 获取到期时间，如果没有，ok则返回false 	Deadline() (deadline time.Time, ok bool) // 返回一个chan，表示取消信号，如果通道关闭则代表该 Context 已经被取消；如果返回的为 nil，则代表该 Context 是一个永远不会被取消的 Context。  Done() &amp;lt;-chan struct{} // 返回该 Context 被取消的原因。如果只使用 Context 包的 Context 类型的话，那么只可能返回 Canceled （代表被明确取消）或者 DeadlineExceeded （因超时而取消）  Err() error // 获取Context中的键值对 	Value(key interface{}) interface{} }   一个demo，引用：通知多个子goroutine退出运行
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  package main import ( &amp;#34;context&amp;#34; &amp;#34;crypto/md5&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type favContextKey string func main() { wg := &amp;amp;sync.</description>
    </item>
    
    <item>
      <title>Go Goroutine和GC</title>
      <link>http://nixum.cc/p/go-goroutine%E5%92%8Cgc/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-goroutine%E5%92%8Cgc/</guid>
      <description>[TOC]
Runtime  不同于Java，Go没有虚拟机，很多东西比如自动GC、对操作系统和CPU相关操作都变成了函数，写在runtime包里。 Runtime提供了go代码运行时所需要的基础设施，如协程调度、内存管理、GC、map、channel、string等内置类型的实现、对操作系统和CPU相关操作进行封装。 诸如go、new、make、-&amp;gt;、&amp;lt;-等关键字都被编译器编译成runtime包里的函数 build成可执行文件时，Runtime会和用户代码一起进行打包。  pprof pprof提供应用运行的过程中分析当前应用的各项指标来辅助进行性能优化以及问题排查功能，提供以下功能
   类型 描述     allocs 查询内存分配情况，所有对象的内存分配，在堆（Heap）分配的时候，记录一下调用堆栈。默认情况下，是每 1000 次分配，取样一次，这个数值可以改变。栈(Stack)分配 由于会随时释放，因此不会被内存分析所记录。由于内存分析是取样方式，并且也因为其记录的是分配内存，而不是使用内存。开启后会对runtime产生压力，通过runtime.MemProfileRate设置采样的内存比例，默认大小是512kb。   blocks 查询阻塞操作情况，类似于 CPU 性能分析，但是它所记录的是 goroutine 等待资源所花的时间。阻塞分析对分析程序并发瓶颈非常有帮助，阻塞性能分析可以显示出什么时候出现了大批的 goroutine 被阻塞了。阻塞性能分析是特殊的分析工具，在排除 CPU 和内存瓶颈前，不应该用它来分析。   cmdline 应用启动命令及参数   goroutine 当前所有协程的堆栈信息，开启时会STW   heap 堆上内存使用情况采样信息，活跃对象的内存分配   mutex 锁持有的堆栈，次数(采样)的信息   profile CPU占用情况采样，启动后会对runtime产生压力，runtime每10ms会STW，记录当前运行的 goroutine 的调用堆栈及相关数据   threadcreate 系统线程创建情况的采样信息，不会STW   trace 程序运行跟踪信息      curl http://ip:port/debug/pprof/{上面列表的功能} &amp;gt; profile文件名 把此时的统计下载下来；</description>
    </item>
    
    <item>
      <title>Go Sync包相关</title>
      <link>http://nixum.cc/p/go-sync%E5%8C%85%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-sync%E5%8C%85%E7%9B%B8%E5%85%B3/</guid>
      <description>[TOC]
变量可见性 由于不同的架构和不同的编译器优化，会发生指令重排，导致程序运行时不一定会按照代码的顺序执行，因此两个goroutine在处理共享变量时，能够看到其他goroutine对这个变量进行的写结果。
happens-before：程序的执行顺序和代码的顺序一样，就算真的发生了重排，从行为上也能保证和代码的指定顺序一样。
Go不像Java有volatile关键字实现CPU屏障来保证指令不重排，而是使用不同架构的内存屏障指令来实现同一的并发原语。
Go只保证goroutine内部重排对读写顺序没有影响，如果存在共享变量的访问，则影响另一个goroutine。因此当有多个goroutine对共享变量的操作时，需要保证对该共享变量操作的happens-before顺序。
证heppen before的手段   init函数：同一个包下可以有多个init函数，多个签名相同的init函数；main函数一定在导入的包的init函数执行之后执行；当有多个init函数时，从main文件出发，递归找到对应的包 - 包内文件名顺序 - 一个文件内init函数顺序执行init函数。
  全局变量：包级别的变量在同一个文件中是按照声明顺序逐个初始化的；当该变量在初始化时依赖其它的变量时，则会先初始化该依赖的变量。同一个包下的多个文件，会按照文件名的排列顺序进行初始化。
init函数也是如此，当init函数引用了全局变量a，运行main函数时，肯定是先初始化a，再执行init函数。
当init函数和全局变量无引用关系时，先初始化全局变量，再执行init函数
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  var ( a = c + b // == 9  b = f() // == 4  c = f() // == 5  d = 3 // 全部初始化完成后 == 5 ) func f() int { d++ return d } --- func init() { a += 1 fmt.</description>
    </item>
    
    <item>
      <title>Go</title>
      <link>http://nixum.cc/p/go/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go/</guid>
      <description>[TOC]
以下基于go.1.14
函数内联优化 函数内联优化：在A函数中调用了B函数，内联后，B函数的代码直接在A函数内原地展开，代替这个函数实现，当有多次调用时，就会多次展开
go在编译时会自动判断函数是否可以内联，当函数内包含以下内容时不会被内联：闭包调用，select，for，defer，go关键字创建的协程等。
内联的好处：因为函数调用被内联了，可以减少栈帧的创建，减少读写寄存器的读取，减少参数和函数的拷贝，提升性能
缺点：堆栈panic显示的行数可能不准确、增加编译出来的包的大小
编译时使用go build -gcflags=&amp;quot;-m -m&amp;quot; main.go可以知道编译器的内联优化策略，
go编译时默认会使用内联优化，使用go build --gcflags=&amp;quot;-l&amp;quot; main.go可禁掉全局内联，如果传递两个或以上-l，则会打开内联；
defer  多个defer是栈的关系，先进后出，即在一个函数中，写在前面的defer会比写在后面的defer调用得晚； defer和return同时出现时，先return后defer，defer可以修改到return里的变量； 遇到panic时，会先遍历此协程内的defer链表，并执行defer，如果在执行过程中遇到recover，则停止panic，返回recover处继续往下执行，如果没遇到recover，则遍历完本协程的defer链表后，向stderr抛出panic信息； 执行defer过程中出现panic，此时的panic会覆盖它之前的panic，直至被捕获或抛出；  内存对齐 CPU读取数据时不会一个字节一个字节去读取，而是一块一块，块的大小可以是2、4、6、8、16字节，块大小称为内存访问粒度。32位CPU一次读取4个字节，64位CPU一次读取8个字节。
如果未进行内存对齐，会导致CPU进行两次内存访问，并且需要花费额外的时钟周期来处理对齐及运算，如果对齐了内存，一次读取就能访问完成，内存对齐可能会耗费额外的空间，但是可以加快读取效率，标准的空间换时间做法。
1 2 3 4 5 6 7 8  type Part1 struct { a bool b int32 c int8 d int64 e byte } // 乍一看按每个类型所占字节数去算，算出来的内存占用是15个字节，但实际上是32字节   对齐规则：
  结构体的成员变量，第一个成员变量的偏移量为 0。往后的每个成员变量的对齐值必须为编译器默认对齐长度（#pragma pack(n)）或当前成员变量类型的长度（unsafe.Sizeof），取最小值作为当前类型的对齐值。其偏移量必须为对齐值的整数倍 结构体本身，对齐值必须为编译器默认对齐长度（#pragma pack(n)）或结构体的所有成员变量类型中的最大长度，取最大数的最小整数倍作为对齐值 结合以上两点，可得知若编译器默认对齐长度（#pragma pack(n)）超过结构体内成员变量的类型最大长度时，默认对齐长度是没有任何意义的   对齐过程：
   成员变量 类型 偏移量 自身占用     a bool 0 1   字节对齐 无 1 3   b int32 4 4   c int8 8 1   字节对齐 无 9 7   d int64 16 8   e byte 24 1   字节对齐 无 25 7   总占用大小 - - 32    内存布局：axxx|bbbb|cxxx|xxxx|dddd|dddd|e，之后要保证整个结构体进行字节对齐，发现它不是2^n，可得出最近一个数是32。</description>
    </item>
    
    <item>
      <title>etcd和ZooKeeper</title>
      <link>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</guid>
      <description>[TOC]
ZooKeeper ZooKeeper保证的是CP，不保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。
使用场景  集群管理，监控节点存活状态 主节点选举，当服务以master-salve模式进行部署，当主节点挂掉后选出新的主节点 服务发现 分布式锁，提供独占锁、共享锁 分布式自增id 搭配Kafka、dubbo等使用  特点  顺序一致性：同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。  数据模型 类似文件系统，根节点为 / ，每创建一个节点会从根节点开始挂，树形结构，每个数据节点称为znode，可以存储数据，每个znode还有自己所属的节点类型和节点状态
  持久节点：一旦创建就一直存在，直到将其删除。 持久顺序节点：一个父节点可以为其子节点 维护一个创建的先后顺序 ，这个顺序体现在 节点名称 上，是节点名称后自动添加一个由 10 位数字组成的数字串，从 0 开始计数。 临时节点：临时节点的生命周期是与 客户端会话 绑定的，会话消失则节点消失 。临时节点 只能做叶子节点 ，不能创建子节点。 临时顺序节点：父节点可以创建一个维持了顺序的临时节点(和前面的持久顺序性节点一样)。   ZAB协议 通过ZAB协议保证注册到ZooKeeper上的主从节点状态同步，该协议有两种模式
  崩溃恢复
当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。
  消息广播
当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案（超过半数同意）来进行事务请求处理。</description>
    </item>
    
    <item>
      <title>Java IO</title>
      <link>http://nixum.cc/p/java-io/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-io/</guid>
      <description>[TOC]
BIO 特点
 BIO是同步阻塞的，以流的形式处理，基于字节流和字符流 每个请求都需要创建独立的线程，处理Read和Write 并发数较大时，就算是使用了线程池，也需要创建大量的线程来处理 连接建立后，如果处理线程被读操作阻塞了，那就阻塞了，只能等到读完才能进行其他操作  以基于TCP协议的Socket，编写服务端Demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  package com.nixum.bio; import java.io.InputStream; import java.</description>
    </item>
    
    <item>
      <title>其他</title>
      <link>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</guid>
      <description>[TOC]
Quartz   分为三个部分：e
 Job&amp;amp;Detial(任务)：定时任务的执行方法，与Trigger配套的 Trigger(触发器)：规定什么时候触发，与Job&amp;amp;Detail配套的 Scheduler(调度器)：单例，把Trigger丢里面由调度器调度，只需要一个Scheduler，配置不同的Trigger；可以理解成类似线程池的东西    原理：ScheduledThreadPoolExecutor线程池 + 通过Object类的wait()和notify()或者Condition类的await()\signal()进行等待和唤醒、锁保证线程安全 来进行调度
Scheduler有两个调度线程：regular Scheduler Thread（执行常规调度）和Misfire Scheduler Thread（执行错失的任务），Regular Thread 轮询所有Trigger，如果有将要触发的Trigger（用wait和notifyAll实现），则从任务线程池中获取一个空闲线程，然后执行与改Trigger关联的job；Misfire Thraed则是扫描所有的trigger，查看是否有错失的，如果有的话，根据一定的策略进行处理
  默认是并发的，即如果当前任务没有完成，会自动开一个任务执行
  注意在分布式集群的情况下，多台机子有相同的定时任务，会出错，此时通过共享数据库的方式实现
Quartz的解决方案：
quartz集群分为水平集群和垂直集群，水平集群即将定时任务节点部署在不同的服务器，其最大的问题就是时钟同步问题，若时钟不能同步，则会导致集群中各个节点状态紊乱，造成不可预知的后果；垂直集群则是集群各节点部署在同一台服务器，时钟同步自然不是问题，但存在单点故障问题，服务器宕机会严重影响服务的可用性
在各个节点会上报任务，存到数据库中，执行时会从数据库中取出触发器来执行，如果触发器的名称和执行时间相同，则只有一个节点去执行此任务。
如果此节点执行失败，则此任务则会被分派到另一节点执行，中途也会自动检查失效的定时调度，发现不成功的，其他节点立马接过来继续完成定时任务。Quartz有11个定时任务调度表
  参考
Quartz原理解密
深入解读Quartz的原理
Quartz 2.2 的实现原理和运行过程
其他定时器  Timer：这是java自带的java.util.Timer类，这个类允许你调度一个java.util.TimerTask任务。使用这种方式可以让你的程序按照某一个频度执行，但不能在指定时间运行。一般用的较少。单线程，任务一多会阻塞；一个任务出异常其他任务都受影响；受系统时间影响 ScheduledExecutorService：也jdk自带的一个类；是基于线程池设计的定时任务类,每个调度任务都会分配到线程池中的一个线程去执行,也就是说,任务是并发执行,互不影响。线程池+延时队列DelayedQueue(数组、最小堆, 最近要执行的任务放在堆顶) 实现，如果堆顶任务时间未到就阻塞（通过自旋+condition.await\signal实现）。不受系统时间影响 Spring 中的 @Schedule 注解  参考：Java 定时任务实现原理详解
Java优先级队列DelayedWorkQueue原理分析
CORS 浏览器的同源政策的同源指的是：协议相同、域名相同、端口相同，如果非同源，有三种行为会受到限制：Cookie、LocalStorage和IndexDB无法读取；DOM无法获得、AJAX请求不能发送。
前后端分离的场景下，由于浏览器的同源策略，导致浏览器内的请求不同的源的后端是会失败，常见的解决跨域方法是使用CORS，现在常见的web框架都支持CORS，开启即可。
解决跨域的方法除了CORS，还有jsonp，不过已经很少使用了，jsonp本质是利用浏览器允许加载不同源的js文件即标签等，将跨域请求标签里，返回一段可执行的js代码，其中包含了请求结果，通常是json格式，前端通过返回的js代码执行回调获取结果。
详情见 跨域资源共享 CORS 详解
对于跨域产生的问题，如CSRF跨域请求攻击的解决方案，可参考：美团:如何防止csrf
session和cookie   首先Http是无状态的，因此需要通过session、cookie来达到记录用户状态的目的。
  传统的session、cookie：session存用户信息，保存在服务端中，cookie里存session对应的sessionId，保存在客户端中，用于找到对应的session，每次请求都会带上该cookie来表示此用户。</description>
    </item>
    
    <item>
      <title>消息队列</title>
      <link>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      <description>[TOC]
使用场景  秒杀系统，一般秒杀系统处理包含几个步骤：风险控制、库存锁定、生成订单、短信通知、更新统计数据等，而决定秒杀是否成功只在前两个步骤，后续的操作就可以通过消息队列异步处理完成，加快整个流程的处理，减少等待时间，提升并发量。 隔离网关和后端服务，实现流量控制，保护后端服务，但会增加系统调用链，导致总体响应变长，异步增加系统复杂性。 令牌桶，目的也是进行流量控制。 服务解耦，数据同步，比如订单系统在订单状态发生变化时发出消息通知，其他服务订阅后做相应处理。 连接流计算任务和数据，比如集群日志处理，大数据统计 将消息广播给其他接收者  好处 流量削峰和流量控制、异步处理、解耦、广播、最终一致性
缺点 可用性降低、复杂度提高、一致性问题、消息延迟
常见消息队列    特性 ActiveMQ RabbitMQ RocketMQ Kafaka     单机吞吐量 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ 10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景   topic数量对吞吐量的影响  使用队列模型，通过Exchange模块实现发布-订阅模型，Exchange位于生产者和队列之间，由Exchange决定将详细投递到哪个队列。 topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源   可用性 高，基于主从架构实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用   消息可靠性 有较低的概率丢失数据  经过参数优化配置，可以做到0丢失 经过参数优化配置，消息可以做到0丢失   时效性 ms级 微秒级，这是rabbitmq的一大特点，延迟是最低的 ms级 延迟在ms级以内   功能支持 MQ领域的功能极其完备 基于erlang开发，所以并发能力很强，性能极其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准   优劣势总结 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。偶尔会有较低概率丢失消息，而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.</description>
    </item>
    
    <item>
      <title>设计模式</title>
      <link>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      <description>[TOC]
只记录常用设计模式
设计模式六大原则  单一职责原则(SRP)：一个类只负责一个功能领域中的相应职责，就一个类而言，应该只有一个引起它变化的原因。 开闭原则(OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 里氏代换原则(LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 依赖倒转原则(DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。如 控制反转和依赖注入 接口隔离原则(ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 迪米特法则(LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。  常见设计模式 创建型模式是将创建和使用代码解耦
结构型模式是将不同功能代码解耦
行为型模式是将不同的行为代码解耦
创建型 单例模式 数据在应用上只保持一份，解决资源访问冲突的问题，就可以使用单例模式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105  /** 1.</description>
    </item>
    
    <item>
      <title>RPC与异步设计</title>
      <link>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</guid>
      <description>[TOC]
RPC  
一个RPC框架的基本实现，高性能网络传输、序列化和反序列化、服务注册和发现，如果是实现客户端级别的服务注册和发现，还可以在SDK中提供容错、负载均衡、熔断、降级等功能。
客户端发起RPC调用，实际上是调用该RPC方法的桩，它和服务端提供的RPC方法有相同的方法签名，或者说实现了相同的接口，只是这个桩在客户端承担的是请求转发的功能，向客户端屏蔽调用细节（比如向发现与注册中心查询要请求的服务方的url），使其像在使用本地方法一样；服务端在收到请求后，由其RPC框架解析出服务名和请求参数，调用在RPC框架中注册的该接口的真正实现者，最后将结果返回给客户端。
一个简单的RPC实现可以由三部分组成：规定远程的接口和其实现，服务端提供接口注册和IO连接，客户端IO连接和接口代理
  首先是定义要提供的远程接口和其实现类
  服务端使用线程池处理IO，实现多路复用，使用socket去循环accept()，每个请求建立一个线程
线程里注册远程接口实例，使用InputStream接收客户端发送的参数，如接口的字节文件，判断是哪个接口，哪个方法，什么参数；接收后反射调用接口方法，将结果通过OutputStream发送回客户端
客户端在发送参数可以做一个封装，加入id，服务端处理得到结果后也加入此id，返回回去，表示此次调用完成
  客户端使用接口，动态代理的方式调用方法，在动态代理的实现里使用IO连接服务端，将远程接口字节码、方法参数这些东西做一个封装发送给服务端，等待返回结果，IO接收是阻塞的
  参考【Java】java实现的远程调用例子 rpc原理
RPC原理及RPC实例分析
异步通信 优点：解耦，减少服务间的依赖，获得更大的吞吐量，削峰，把抖动的吞吐量变得均匀。
缺点：业务处理变得复杂，比如引入新的中间件，意味着要维护多一套东西，有时可能还得保证消息顺序，失败重传，幂等等处理，比较麻烦；异步也导致了debug的时候比较麻烦；
定时轮询 发送方请求接收方进行业务处理，接收方先直接返回，之后接收方在自己处理，最后将结果保存起来，发送方定时轮询接收方，获取处理结果。
回调 发送方请求接收方进行业务处理时，带上发送方结果回调的url，接收方接收到请求后先立刻返回，之后接收方在自己处理，当处理结果出来时，调用发送方带过来的回调url，将处理结果发送给发送方。
同理在于服务内部的异步回调，也是如此，只是把url换成了callback方法，比如Java中的Future类+Callable类。
发布订阅 主要靠消息队列实现，不过比较适合发送方不太care处理结果的，如果care处理结果，可以再通过一条队列将结果传递下去，执行后面的处理。
事件驱动 + 状态机 可以依靠消息队列，本质还是发布订阅那一套，只是将触发的条件换成事件，消费者根据不同的事件触发不同的逻辑，然后再通过状态机保证处理事件顺序。
比较常见的场景是电商业务中围绕订单服务的一系列业务处理，比如订单创建完成后，订单服务发出订单创建的事件，对应库存服务，收到该事件，就会进行锁库操作等
事件驱动模型 实际上是使用了观察者模式和状态模式来实现的，比较直观的例子就是android的EventBus，chrome的V8引擎都有用到此模型，这里仅总结并进行简单介绍
 
这里的demo是项目中使用到的组件的一个简化，真实的组件要比这个复杂的多，这里只简单罗列出基本的原理和优缺点。
原理：
 事件驱动-状态机的异步模型，本质上是底层controller维护一个阻塞队列，将外部请求转化为事件，通过事件在内部传递。 controller接收到请求，从对象复用池中获取一个上下文context并init，然后将事件交由context处理。context内有一套状态的扭转的控制流程，在不同的状态接收事件对业务逻辑进行处理，最后将处理结果交由注册的回调函数异步或者同步返回。 每一个状态在处理完当前逻辑操作后将发送事件给阻塞队列，并扭转为下一个状态，等待下一个事件的到来。 由于controller是单线程的，各个状态在处理的时候要求速率尽可能的快，以至于不会阻塞主线程，因此在controller内部还维护了一个延迟队列，用来接收延迟事件，状态通常在进行业务处理前会起一个定时器，如果超时将发送延迟事件给到延迟队列，来避免当前操作过长导致阻塞主线程，定时器由下一个状态来取消。 一般会为每个请求分配id，每个id对应一个上下文context，上下文一般使用id + Map来实现同一个请求下的上下文切换、保存和恢复，使用对象复用池来避免上下文对象频繁初始化 这套模型一般应用在中间件的设计上，当然也可以抽成通用框架，在写的时候就会发现，其实变化最多的是状态流程那一块，所以完全可以把这块抽出来 + netty进行网络通信就能搭出一套web框架出来了  优点：
  是一个单线程的模型，本身就是线程安全的。
  理论上一套业务逻辑拆分成小逻辑，交由不同的状态操作，各个状态的操作时间要求尽可能的短，不然会阻塞主线程
  各个状态在进行逻辑操作时，如果处理的时间过长，一般会使用线程池+回调+事件的方式处理
  状态机模式对应业务逻辑流程有比较强的控制，各个状态对应不同的职责
  对CPU的利用率比较高，吞吐量比较高，因为可以一次处理多种业务请求，每个业务请求都能进行拆分进行异步处理，速率比较快，因此性能会比常用的Spring全家桶好很多吧，至少在项目使用中的感受是这样</description>
    </item>
    
    <item>
      <title>分布式相关</title>
      <link>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</guid>
      <description>[TOC]
分布式理论 一个分布式系统最多只能满足 C、A、P 这三项中的两项。
CAP理论 CAP特性
 C：Consistency，一致性，数据状态转化一致，写操作完成后的读操作，可以获取到最新的值 A：Availability，可用性，指的是服务一直可用，可以正常响应 P：Partition tolerance，分区容错，指的是当有节点故障不连通时，就会分区，但仍然能对外提供服务  矛盾在于这三个特性不能同时满足，比如
 当分布式集群内有两个主从服务发生网络故障，但此时服务仍然可以访问，此时具有分区容错性。
当对主服务对数据进行修改时，由于网络问题，无法同步到从服务，当访问到从服务时，无法获取到最新的值，此时满足可用性，但是无法满足一致性。
当主从服务间网络恢复，写操作的数据虽然能在服务间同步了，但还未同步完成，此时访问从服务无法获取最新值，此时满足了一致性，但是无法满足可用性。
简单概括，只要满足分区容错，就会设置复制集，复制集同时也保证了可用，但是复制集又会有数据同步，此时又有一致性问题
 所以，一般只会满足其中两个
 1、满足CA舍弃P，也就是满足一致性和可用性，舍弃容错性。但是这也就意味着你的系统不是分布式的了，因为涉及分布式的想法就是把功能分开，部署到不同的机器上。
2、满足CP舍弃A，也就是满足一致性和容错性，舍弃可用性。如果你的系统允许有段时间的访问失效等问题，这个是可以满足的。就好比多个人并发买票，后台网络出现故障，你买的时候系统就崩溃了。
3、满足AP舍弃C，也就是满足可用性和容错性，舍弃一致性。这也就是意味着你的系统在并发访问的时候可能会出现数据不一致的情况。
 所以为了分布式服务能正常使用，一般时会满足分区容错性和可用性，在一致性上不追求强一致性，而是一个逐渐一致的过程。
BASE理论 BASE理论是对CAP三者均衡的结果，基于CAP理论演化而来，通过牺牲强一致性来获得高可用。
 Basically Available（基本可用）: 允许暂时不可用，比如访问时可以等待返回，服务降级，保证核心可用等。 Soft state（软状态）: 允许系统存在中间状态，而该中间状态不会影响系统整体可用性，比如允许复制集副本间的数据存在延时，数据库的数据同步过程。 Eventually consistent（最终一致性）: 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。  与数据库ACID类似，只是强度减弱了
参考：CAP 定理的含义
关于可靠性、可用性、稳定性   可靠性Reliability：不出事故，故障率低，关注的是系统无故障地持续运行的概率，比如
  MTBF（Mean Time Between Failure）：即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。MTBF越长表示可靠性越高，正确工作能力越强 。
  MTTR（Mean Time To Repair）：即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。MTTR越短表示易恢复性越好。
  MTTF（Mean Time To Failure）：即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。系统的可靠性越高，平均无故障时间越长。
  与可用性的关系：Availability = UpTime/(UpTime+DownTime) = MTBF / (MTBF + MTTR)</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>http://nixum.cc/p/redis/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/redis/</guid>
      <description>[TOC]
数据类型及结构 数据类型 Redis所有类型有一个顶层的数据结构叫RedisObject，这个RedisObject底层对应着具体对象类型和其编码方式。
之所以有RedisObject对象，是因为每种不同的数据类型有不同的编码方式和结构，Redis必须让每个键都带有类型信息，使得程序可以检查键的类型，还需要根据数据类型的不同编码进行多态处理。
比如：SADD命令只能用于Set，LPUSH命令只能用于List，而DEL、TTL又能用于所有键，要正确实现这些命令，就需要为不同类型的键设置不同的处理方式；另外，同一种数据类型可能由不同的数据结构实现，比如List，底层可能是压缩列表或者双向链表，因此还需要知道数据类型的编码方式。
 
1 2 3 4 5 6 7 8 9 10 11 12 13  typedef struct redisObject { // 类型，如String、List  unsigned type:4; // 编码方式：SDS、压缩列表  unsigned encoding:4; // LRU - 24位, 记录最后一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间）  unsigned lru:LRU_BITS; // LRU_BITS: 24  // 引用计数，新创建对象时值为1，当对该对象进行共享时值+1，使用完一个对象后值-1，=0时被GC回收  int refcount; // 指向底层数据结构实例，具体的实例，由type和encoding决定  void *ptr; } robj;    当执行一个处理数据类型命令的时候，redis执行以下步骤
 根据给定的key，在数据库字典中查找和他相对应的redisObject，如果没找到，就返回NULL； 检查redisObject的type属性和执行命令所需的类型是否相符，如果不相符，返回类型错误； 根据redisObject的encoding属性所指定的编码，选择合适的操作函数来处理底层的数据结构； 返回数据结构的操作结果作为命令的返回值   Redis本身还会预分配一些值对象，比如响应结果OK、ERROR，还有包括0在内，所有小于REDIS_SHARED_INTEGERS（默认值是10k）的所有整数，共享对象只能被字典或双向链表这类带有指针的数据结果使用。</description>
    </item>
    
    <item>
      <title>Kubernetes和Istio</title>
      <link>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</guid>
      <description>[TOC]
Kubernetes 当前Kubernetes社区对外宣传是单个集群最多支持5000个节点，Pod总数不超过150k，容器总数不超过300k，单节点Pod数量不超过100个。
基本  
容器的本质是进程，Kubernetes相当于操作系统，管理这些进程组。
  CNI：Container Network Interface，容器网络接口规范，如 Flannel、Calico、AWS VPC CNI
  CRI：Container Runtime Interface，容器运行时的各项核心操作的接口规范，是一组gRPC接口。包含两类服务，镜像服务和运行时服务。镜像服务提供下载、检查和删除镜像的RPC接口；运行时服务包含用于管理容器生命周期，与容器交互的调用的RPC接口（exec / attach / port-forward等）。dockershim、containerd、cri-o都是遵循CRI的容器运行时，称为高层级运行时。
  CSI：Container Storage Interface，容器存储的接口规范，如PV、PVC
  OCI：Open Container Initiative，容器运行时和镜像操作规范，镜像规范规定高层级运行时会下载一个OCI镜像，并把它解压称OCI运行时文件系统包；运行时规范描述如何从OCI运行时文件系统包运行容器程序，并且定义其配置、运行环境和生命周期。定义新容器的namespaces、cgroups和根文件系统；它的一个参考实现是runC，称为底层级运行时。
  CRD：Custom Resource Definition，自定义的资源对象，即yaml文件中的Kind，如Operator就是实现CRD的控制器，之后直接使用Operator创建的CRD声明对象即可使用
每一个对象都包含两个嵌套对象来描述规格（Spec）和状态（Status），对象的规格就算我们期望的目标状态，而状态描述了对象当前状态，这一部分由Kubernetes本身提供和管理，通过describe才能看到Status的信息。
1 2 3 4 5 6 7  type Deployment struct { metav1.TypeMeta `json:&amp;#34;,inline&amp;#34;` metav1.ObjectMeta `json:&amp;#34;metadata,omitempty&amp;#34; protobuf:&amp;#34;bytes,1,opt,name=metadata&amp;#34;` Spec DeploymentSpec `json:&amp;#34;spec,omitempty&amp;#34; protobuf:&amp;#34;bytes,2,opt,name=spec&amp;#34;` Status DeploymentStatus `json:&amp;#34;status,omitempty&amp;#34; protobuf:&amp;#34;bytes,3,opt,name=status&amp;#34;` }     Master节点作用：编排、管理、调度用户提交的作业</description>
    </item>
    
    <item>
      <title>MySQL</title>
      <link>http://nixum.cc/p/mysql/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mysql/</guid>
      <description>[TOC]
基础架构 MySQL逻辑架构图  
 连接器：负责跟客户端建立连接、获取权限、维持和管理连接。登录进去后修改权限，默认是将在下一次登录后生效 查询缓存：MySQL接收到查询请求后会先查询缓存，key是查询语句，value是查询结果，之后经过执行器的权限判断再返回，如果查不到则往后走。不建议使用，因为若有更新操作，会删除对应表的缓存，可能导致缓存命中低，可以设置query_cache_type=demand，默认不使用缓存，需要在查询时显示指定。MySQL8.0删除此功能 分析器：对SQL语句进行分析，词法分析判断各个字符串代表的含义（包括列是否存在），语法分析判断SQL的语法是否正确，这一层操作之后，MySQL就知道你要做什么了 优化器：决定是否要使用索引，使用哪个索引，决定表的连接顺序 执行器：先判断是否有对该表的操作权限，之后判断要使用哪个引擎提供的接口 引擎：对数据进行具体操作的执行者，事务和索引都是在这层做的，但具体需要引擎支持，例如MyISAM不支持事务，InnoDB支持  日志系统   redo log重做日志：InnoDB独有，物理日志，记录这个页做了什么改动，使用二阶段提交保证两份日志逻辑一致。记录写入到redo log buffer后状态是prepare，binlog写入磁盘，事务提交，redo log改为commit状态，commit后才写进redo log(磁盘)
当有记录要更新的时候，InnoDB会先把记录(包含数据变更和change buffer的变更)写到redo log里，并更新内存，再在恰当的时候更到磁盘里，redo log prepare、commit 的XID对应bin log的XID实现关联。
InnoDB的redo log是固定大小的，比如有一组4个文件组成的“环形队列”，首位指针表示当前记录的位置和当前擦除位置，擦除前会把记录更新到磁盘，这种能力也称为crash-safe
建议设置innodb_flush_log_at_trx_commit=1，表示每次事务的redo log会持久化到磁盘
  bin log归档日志：属于server层的日志，逻辑日志，记录所有逻辑操作，追加写入，不会覆盖以前的日志，bin log有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，一般使用row，记录行变化前和变化后的数据，缺点是日志变大。从库是使用bin log进行备份的
建议设置sync_binlog=1，表示每次事务的bin log都会持久化到磁盘
  可以只使用redo log来实现崩溃恢复，但无法只使用bin log，原因是 InnoDB使用WAL机制（执行事务时，将操作记录写入内存和日志，事务就完成了，此时数据可能还没写入磁盘，MySQL会在合适的时机将内存里的数据刷入磁盘），如果此时数据库崩溃，要依赖日志来恢复数据页，但是bin log并没有记录数据页的更新细节，而redo log因为环形写入的问题，无法对所有记录进行归档，仅仅只能实现崩溃恢复
备份时间的长短会影响日志文件的大小，文件的完整性，从而影响到恢复速度和恢复效果
 undo log回滚日志：InnoDB独有，逻辑日志，主要用于事务失败时的回滚，以及MVCC中版本数据查看。当事务被提交后，并不会马上被删除，而是放到待清理链中，=到没有事务用到该版本信息时才可以清理。  参考：MySQL中的日志机制
常用SQL Count(*)、Count(1)、Count([列])区别 在count(*)不带条件在MyISAM里查询比较快，因为MyISAM会存储总条数，不带条件查询的时候直接用就行，而InnoDB带了事务，支持MVCC，因此每次count(*)时都会扫表
以下归纳基于InnoDB，count会返回满足条件的结果集的总行数，它会使用存储引擎进行全表扫描获取结果，比如count(1)会直接返回1，count(主键)会获取主键，返回给server层，由server层进行计数，因此按效率排序是：count(字段) &amp;lt; count( 主键id) &amp;lt; count(1) ≈ count(*)
 count（列）会计算列或这列的组合不为空的计数 count(*) 跟 count(1) 的结果一样，都包括对NULL的统计，而count([列名]) 是不包括NULL的统计 对于计数，也可以通过创建列为表名、total的表进行计数，利用事务能力，一般是先insert在update，理由是并发进行total值的更新时，是会上行锁的，如果先update total值可能会导致事务处理时间过长  having的使用   having一般需要搭配 group by 使用，在group by之后，order by之前</description>
    </item>
    
    <item>
      <title>操作系统</title>
      <link>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>[TOC]
内核 PC机启动流程 以Ubuntu Linux + GRUB引导程序为例：
PC机加电后，加载BIOS固件， 触发PC机BIOS固件发送指令 检测和初始化CPU、内存及主板平台，加载引导设备(比如硬盘)中的第一个扇区数据到0x7c00地址开始的内存空间，再接着跳转到0x7c00处执行指令，加载GRUB引导程序，加载硬盘分区中的OS文件，启动操作系统。
内核结构分类 内核：计算机资源的管理者。计算资源分为硬件资源和软件资源
  硬件资源：CPU、内存、硬盘、网卡、显卡、IO设备、总线，他们之间通过总线进行联系；
  软件资源：对上述各种硬件资源的管理程序、设备的驱动程序
  宏内核结构 - 类似单体服务 将上述所有软件资源进行整合，链接在一起，形成一个大的可执行程序，控制所有硬件资源。这个大程序会在处理器的特权模式下运行，对外提供系统调用函数，供其他程序、进程调用。
当应用层有程序要调用进行内存分配时，就会调用宏内核进行内存分配
 应用程序调用内核内存分配API函数 处理器切换到特权模式，开始运行内核代码 内核的内存管理代码按照特定的算法，分配内存 内存分配函数把分配的内存块的首地址返回给应用程序 应用程序接收到返回后，处理器开始运行用户模式下的应用程序，应用程序使用得到的内存首地址，开始使用这块内存  优点：由于所有硬件管理程序都整合在一起，相互调用时性能极高
缺点：所有硬件管理程序都整合在一起，没有模块化，扩展性差，移植性差，牵一发而动全身，每次修改都需要重新安装，其中一个模块有问题就会影响其他模块。
Linux就属于宏内核
 Linux 的基本思想是一切都是文件：每个文件都有确定的用途，包括用户数据、命令、配置参数、硬件设备等对于操作系统内核而言，都被视为各种类型的文件。Linux 支持多用户，各个用户对于自己的文件有自己特殊的权利，保证了各用户之间互不影响。多任务则是现代操作系统最重要的一个特点，Linux 可以使多个程序同时并独立地运行。
 第一次访问 
Linux使用宏内核架构，主要分为上述五大模块，模块间的通信通过函数调用，函数间的调用没有层次关系，所以函数的调用路径纵横交错，如果有函数出问题，那就会影响到调用它的模块，存在安全隐患，但优点是存内核调用，性能极高
Linux高清全结构图：https://makelinux.github.io/kernel/map/
 微内核结构 - 类似微服务 内核仅处理进程调度、中断、内存空间映射、进程间通信等，控制硬件资源的软件资源，转成一个个服务进程，比如进程管理、内存管理、设备管理、文件管理等，和用户进程一样，只是它们提供了宏内核的那些功能。
微内核内，进程间通过消息进行通信，应用程序每次要申请资源都需要发送消息到微内核，微内核再把这条消息转发给相关服务进程，直到完成这次调用。
当应用层有程序要调用进行内存分配时
 应用程序发送内存分配的消息（发送消息这个函数由微内核提供） 处理器切换到特权模式，执行内核代码 微内核让当前进程停止运行，并根据消息包中的数据，推送给对应的消息接收者，比如这里是内存管理服务进程。 内存管理服务进程收到消息，分配一块内存 内存管理服务进程，处理完成后，通过消息的形式返回分配内存块的地址给内核，然后继续等待下一条消息。 微内核把包含内存地址的消息返回发送给内存分配消息的应用程序 处理器开始运行用户模式下的应用程序，应用程序收到这条消息，得到内存首地址，开始使用这块内存。  优点：系统结构清晰，移植性、伸缩性、扩展性强，微内核代码少，容易替换，各种系统服务进程可随时替换
缺点：进程间消息依赖微内核进行消息传递，会频繁进行服务进程切换，模式切换，导致性能较差。
分离硬件的相关性 分离硬件的相关性其实就是屏蔽底层硬件操作细节，形成一个独立的软件抽象层，对外提供接口，方便应用层接入。
是内核设计的一种指导思想，所以在设计操作系统内核的时候，就可以分为
 内核接口层：向应用层提供系统接口函数； 内核功能层：系统函数的主要实现，实现进程管理、内存管理、中断管理、设备管理、驱动、文件系统等； 内核硬件层：对硬件资源的操作，比如初始化CPU、内存、中断控制、其他IO设备  混合内核 混合内核在微内核的基础上进行改进，层次分明，动态加载模块到内核，兼具宏内核和微内核的优点。</description>
    </item>
    
    <item>
      <title>网络</title>
      <link>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</guid>
      <description>[TOC]
基本    OSI七层模型 对应网络协议 作用     应用层 HTTP、TFTP、FTP、NFS、SMTP、Telnet 应用程序间通信的网络协议   表示层 Rlogin、SNMP、Gopher 数据格式化、加密、解密   会话层 SMTP、DNS 建立、维护、管理会话连接   传输层 TCP、UDP 建立、维护、管理端到端连接   网络层 IP、ICMP、ARP、RARP、AKP、UUCP IP寻址和路由选择   数据链路层 FDDI、Ethernet、Arpanet、PDN、SLIP、PPP 控制网络层与物理层间的通信   物理层 IEEE 802.1A、IEEE 802.2到802.11 比特流传输    数据链路层：
 数据包叫Frame，“帧”； 由两部分组成：标头和数据，标头标明数据发送者、接收者、数据类型； 用MAC地址定位数据包路径； 相关设备是交换机；  网络层：
 数据包叫packet，“包”； IPv4：32个二进制，4字节*8位；IPv6：1同一子网28个二进制，8字节*16位； 子网掩码与IP的and运算判断是否为同一子网下； 路由：把数据从原地址转发到目标地址，同一局域网内，通过广播的方式找到，不同局域网内，原主机先将包根据网关添加路由器/主机地址，通过交换机的广播方式发给目标主机，原主机将数据包传输给目标主机，再由目标主机根据MAC广播交给对应目标 ARP协议：IP与MAC地址的映射，仅限IPv4，IPv6使用 Neighbor Discovery Protocol替代； 相关设备是路由器，网关  传输层：</description>
    </item>
    
    <item>
      <title>UML</title>
      <link>http://nixum.cc/p/uml/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/uml/</guid>
      <description>[TOC]
类图 类图中的关系其实有多种版本的表示方法，这里仅总结自己常用的画法
访问作用域   + : public
  - : private
  # : protocted
  关系 1. 依赖（dependency） 依赖关系是五种关系中耦合最小的一种关系。
依赖在代码中主要体现为类A的某个成员函数的返回值、形参、局部变量或静态方法的调用，则表示类A引用了类B。
A &amp;mdash;-&amp;gt; B ： A use B （虚线+箭头）
 A use B 
2. 关联（Association） 在程序代码中，具有关联关系的类常常被声明为类的引用类型的成员变量。
因为 关联 是 依赖 的更详细说明， 关联 是专门描述成员属性的关系，所以依赖中所有涉及成员属性的地方更适合使用：关联、聚合、组合
单向关联：
A ——————&amp;gt; B ： A has B （实心线 + 箭头）
 A has B 
3. 聚合（Aggregation） 聚合是关联的一种特殊形式，暗含整体/部分关系，但是对方却不是唯一属于自己的那种关系。 用来表示集体与个体之间的关联关系，例如班级与学生之间存在聚合关系。
A &amp;lt;&amp;gt;—————— B : A是集体，B是个体 （实线 + 空心菱形）</description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>http://nixum.cc/p/jvm/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/jvm/</guid>
      <description>[TOC]
JVM内存模型  JVM内存模型 
方法区也叫永久代，持久代，非堆，不算在堆里面
年轻代也叫新生代
注意区别于Java内存模型
JVM内存模型描述的是线程运行时的数据在内存的分布
Java内存模型是多线程情况下数据的分布
引用类型  强引用：通过new的方式创建，不会被轻易回收 软引用（SoftReference）：被软引用关联的对象只有在内存不够时才会被回收 弱引用（WeakReference）：被弱引用关联的对象一定会被回收，只能存活至下次垃圾回收发生之前 虚引用（PhantomReference）：比如将对象引用设置为null，该引用指向的对象就会被回收，相当于告知JVM可以回收该对象  软引用、弱引用、虚引用均可以搭配引用队列使用，且虚引用必须搭配引用队列使用。使用引用队列时，这些引用对象被垃圾收集器回收之后会进入引用队列，等待二次回收。引用队列一般用于与GC交互的场景，比如，垃圾回收时进行通知。
可达性分析 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收，不可达指的是游离在GC Root外的对象。
GC Roots包括：
  java虚拟机栈中引用的对象
方法执行时，JVM会创建一个相应的栈帧进入java虚拟机栈，栈帧中包括操作数栈、局部变量表、运行时常量池的引用、方法内部产生的对象的引用，当方法执行结束后，栈帧出栈，方法内部产生的对象的引用就不存在了，此时这些对象就是不可达对象，因为无法从GC Roots找到，这些对象将在下次GC时回收。
比如，方法内部创建一个对象A，并持有另一个对象B，对象B引用也同时被其他线程持有，然后在方法里设置对象A=null或者方法结束后，个人认为对象A会被回收，对象B不会被回收，如果是方法外有一个对象C引用了对象A，设置对象A=null或方法结束后，对象A不会被回收
  方法区中类静态属性引用的对象、常量引用的对象
静态属性或者静态变量，是class的属性，不属于任何实例，该属性会作为GC Roots，只要该class存在，该引用指向的对象也会一直存在，只有该class被卸载时，才会被回收。对于常量池里的字面量，当没有其他地方引用这个字面量时，也会被清除。
  本地方法栈中Native方法引用的对象
这部分属于其他语言写的方法所使用到的对象，道理跟上面是java虚拟机栈是类似的
  垃圾回收算法 引用计数法 为对象添加一个引用计数器，当对象增加一个引用时，计数器加 1，引用失效时，计数器减 1。引用计数为 0 的对象可被回收。
比较轻便，效率较高，不需要STW，可以很快进行回收，但维护引用计数也有一定的成本
但有可能出现循环引用，JVM没有使用该判断算法，可能因为编译的时候并不会检测对象是否存在循环引用？go的话会在编译期检测是否存在循环引用，但是它垃圾回收使用三色标记法，本质是标记清除
复制 标记-清理 标记 - 整理 三色标记   把所有对象放到白色的集合中 从根节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中 遍历灰色集合对象，把灰色对象引用的白色集合的对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色集合中 循环步骤3，直到灰色集合中没有对象 步骤4结束后，白色集合中的对象为不可达对象，进行回收   参考：深入理解Go-垃圾回收机制
垃圾收集器 CMS 执行过程   初始标记(STW initial mark)：这个过程从垃圾回收的&amp;quot;根对象&amp;quot;开始，只扫描到能够和&amp;quot;根对象&amp;quot;直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记(Concurrent marking)：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 并发预清理(Concurrent precleaning)：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段&amp;quot;重新标记&amp;quot;的工作，因为下一个阶段会Stop The World。 重新标记(STW remark)：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从&amp;quot;跟对象&amp;quot;开始向下追溯，并处理对象关联。 并发清理(Concurrent sweeping)：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。 并发重置(Concurrent reset)：这个阶段，重置CMS收集器的数据结构状态，等待下一次垃圾回收。   G1 执行过程   标记阶段：首先是初始标记(Initial-Mark),这个阶段也是停顿的(stop-the-word)，并且会稍带触发一次yong GC。 并发标记：这个过程在整个堆中进行，并且和应用程序并发运行。并发标记过程可能被yong GC中断。在并发标记阶段，如果发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，每个区域的对象活性(区域中存活对象的比例)被计算。 再标记：这个阶段是用来补充收集并发标记阶段产新的新垃圾。与之不同的是，G1中采用了更快的算法:SATB。 清理阶段：选择活性低的区域(同时考虑停顿时间)，等待下次yong GC一起收集，对应GC log: [GC pause (mixed)]，这个过程也会有停顿(STW)。 回收/完成：新的yong GC清理被计算好的区域。但是有一些区域还是可能存在垃圾对象，可能是这些区域中对象活性较高，回收不划算，也肯能是为了迎合用户设置的时间，不得不舍弃一些区域的收集。   内存分配和回收策略  1.</description>
    </item>
    
    <item>
      <title>Spring和SpringBoot</title>
      <link>http://nixum.cc/p/spring%E5%92%8Cspringboot/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/spring%E5%92%8Cspringboot/</guid>
      <description>[TOC]
SpringBoot Spring 和 Spring Boot区别 Spring Boot实现了自动配置，降低了项目搭建的复杂度。它主要是为了解决使用Spring框架需要进行大量的配置太麻烦的问题，所以它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，做到零配置即用。内置Tomcat作为Web服务器，不像之前还要把服务部署到Tomcat在进行启动。
SpringBoot整个启动流程  构建SpringApplication对象，执行其run方法 加载properties/yaml等配置文件 创建ApplicationContext（也可以称为Bean、IOC容器） 将扫描到的Bean或者xml中的bean，先解析成BeanDefinition，注册到ApplicationContext中的BeanFactory中（即自动配置过程，也是IOC容器的refresh方法执行过程） 实例化Bean，进行依赖注入，（AOP也是在此处实现，创建代理实例加入IOC容器）   SpringBoot启动流程 
参考SpringBoot启动流程解析
SpringBoot启动流程
SpringBoot自动配置流程 自动配置流程只是SpringBoot启动中的一个环节，该环节只是在告诉Spring要在哪里找到Bean的声明。
启动类main方法为入口，main方法所在的类会被**@SpringBootApplication**修饰， 通过main方法里执行**SpringApplication.run(Application.class, args)**进行启动，Spring启动时会解析出@SpringBootApplication注解，进行Bean的加载和注入。
  @SpringBootApplication里包含了
  @SpringBootConfiguration：作用类似于**@Configuration**，JavaConfig配置类，相当一个xml文件，配合@Bean注解让IOC容器管理声明的Bean
  @ComponentScan：配上包路径，用于扫描指定包及其子包下所有类，如扫描@Component、@Server、@Controller等，并注入到IOC容器中
  @EnableAutoConfiguration：自动配置的核心注解，主要用于找出所有自动配置类。该注解会使用**@Import(EnableAutoConfigurationImportSelector.class**)帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。
    EnableAutoConfigurationImportSelector类里有个SpringFactoriesLoader工厂加载器，通过里面的loadFactoryNames方法，传入工厂类名称和对应的类加载器，加载该类加载器搜索路径下的指定文件spring.factories文件，传入的工厂类为接口，而文件中对应的类则是接口的实现类，或最终作为实现类，得到这些类名集合后，通过反射获取这些类的类对象、构造方法，最终生成实例。
因此只要在maven中加入了所需依赖，根据spring.factories文件里的key-value，能够在类路径下找到对应的class文件，就会触发自动配置
  自定义starter 实际上就是编写自动配置类，会使用到一系列配置注解，如@Configuration、@EnableConfigurationProperties、@Component、@Bean、@ConditionOnXX、@AutoConfigureOrder等，让IOC容器加载我们自定义的Bean进去；
另外就是必须在META-INF文件夹下创建spring.factories，告知Spring在哪找到配置类。
org.springframework.boot.autoconfigure.EnableAutoConfiguration=[自定义配置类的全限定名称] 自定义Starter可以理解为一个Jar包，该Jar包在Maven或Gradle注册后，服务启动时，IOC容器会去自动加载。
自定义Starter内也可以使用配置文件，设定默认配置的key-value，当本项目里有配置的key与starter里定义的配置key重复时可以被替换
ContextLoaderListener 【Spring】浅谈ContextLoaderListener及其上下文与DispatcherServlet的区别
 作为Spring启动入口 实现了ServletContextListener 接口，监听ServletContext，如果 ServletContext 发生变化（如服务器启动时ServletContext 被创建，服务器关闭时 ServletContext 将要被销毁）时，执行监听器里的方法 为IOC容器提供环境，扫描包，将带有注解的Bean加入到容器用于依赖注入，或者加载xml文件，将xml注册的bean加入容器用于依赖注入  常用注解 @Controller与@RestController  @Controller 默认是返回视图，即方法的return返回的是视图层的路径，只有+@ResponseBody才会返回Json格式的数据 @RestController实际上是@Controller + @ResponseBody组合，默认返回json格式的数据  @Autowired与@Resource   @Autowired 注解，修饰类成员变量、方法及构造方法，完成自动装配的工作，默认按 byType 自动注入。只有一个required属性，默认是true，表示必须注入，不能为null</description>
    </item>
    
    <item>
      <title>Java并发</title>
      <link>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</guid>
      <description>[TOC]
线程、进程、协程   进程：可以简单理解为一个应用程序，进程是资源分配的基本单位。比如一个进程拥有自己的堆、栈、虚存空间、文件描述符等。
涉及到用户态和内核态的切换。
进程间的通信：
 匿名管道：半双工，数据只能向一个方向流动，双方需要通信时，需要建立起两个管道；且只能用于有亲缘关系的进程；本质是一个内核缓冲区，可以看成是内存中的文件，但不属于某种文件系统，无需显示打开，创建时直接返回文件描述符，读写时需要确定对方的存在，否则将退出；以先进先出的方式存取数据，通信的双方需制定好数据的格式； 有名管道：主要解决匿名管道只能作用与有亲缘关系的进程的问题，通过一个路径名关联，以文件形式存在于文件系统中，即使没有亲缘关系的进程也能通过访问路径实现通信；管道名字存在于文件系统中，内容存在内存中；打开时就得确定对方是否存在，否则将阻塞； 信号：操作系统提供的一种机制，可以在任何时候发给某一进程，而无需指定该进程的状态，如果该进程当前处于未执行状态，该信号就由内核保存起来，直到进程回复执行并传递为止；信号接收可以被阻塞，直到阻塞解除；本质是对中断机制的模拟，异步通信，在用户态和内核态之间交互；能携带的信息较少。 消息队列：存放在内核中的消息链表，只有在内核重启或显示地删除时，才会被真正的删除，与管道不同的是消息队列不需要确定接收进程是否存在；一般是FIFO，但也可以实现成随机查询；对消息格式，缓冲区大小等都能进行控制，比管道灵活； 共享内存：没什么好说的，只是在访问共享内存时要依靠一些同步或互斥机制保证并发访问安全； 信号量：计数器，一般用于多进程对共享内存访问的保护，内核中实现，保证原子操作 套接字：通信机制，可用在本机或者跨网络，由域、端口号、协议类型三个属性确定；域分为AF_INET，即网络，另一个是AF_UNIX，即文件系统    线程：线程是独立调度的基本单位，由CPU进行调度和执行的实体。一个进程中可以有多个线程，线程之间共享进程资源，是进程中的实际运作单位。
涉及到用户态和内核态的切换。
  协程：GoLang中的协程
 在用户态层面，由线程控制，即用户应用层面自己控制，很难像抢占式调度那样强制CPU切换到其他线程/进程，只能是协作式调度，但同时也避免了上下文切换 内存消耗比线程小，比如go开启协程是几kb，java开启一个线程至少1MB 实现原理：在一个运行的线程上，起多个协程，每个协程会加入到调度队列中，线程会从调度队列里取出协程进行运行。队列个数默认取决于CPU的个数，协程间的切换会线程使用go提供的io函数进行控制。当有协程执行较慢时，会先将其挂起，然后唤醒其他线程，将未处理的协程队列转移到该线程，消费队列里的协程，当队列消费完成后，再切回原来的线程，继续执行刚刚挂起的协程。    参考：图解Go协程调度原理，小白都能理解 
Golang 的 goroutine 是如何实现的？
进程与线程的区别   拥有资源
进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
  调度
线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
  系统开销
由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
  通信方面
线程间可以通过直接读写同一进程中的数据进行通信，在java中如使用共享变量、wait/notify机制、阻塞队列；但是进程通信需要借助管道、消息队列、共享存储、信号量、信号、套接字socket
  上下文切换的开销
当CPU从执行一个线程切换到执行另外一个线程的时候，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。这种切换称为“上下文切换”(“context switch”)。CPU会在一个上下文中执行一个线程，然后切换到另外一个上下文中执行另外一个线程。
调度方式  非抢占式：系统一旦开始执行某一进程，就会让该线程就会一直执行下去，直至完成，或者发生了其他事件导致系统放弃对该进程的执行后，才会去执行另外一个进程。 抢占式：系统执行某一进程，在其执行期间，系统可以立即停止当前进程，转而执行另外一个进程，待处理完后，重新回来继续执行之前停止的进程  调度原理 用户空间线程和内核空间线程之间的映射关系</description>
    </item>
    
    <item>
      <title>git</title>
      <link>http://nixum.cc/p/git/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/git/</guid>
      <description>git流程 
常用命令   git init
将一个普通文件夹变成git仓库，此时文件夹下多出.git文件夹，表示可以使用git管理，此时这个文件夹称为git工作区
或者
使用git clone url(github上的仓库链接)将仓库从github上下载下来
  当对工作区内的文件做出修改后   git add 文件名
表示将该文件的修改加入到暂存区
  git add .
(注意后面有个 . )表示将当前目录下的所有文件的修改都加入到暂存区
  git commit -m &amp;ldquo;备注信息&amp;rdquo;
表示将暂存区的修改提交到当前分支，提交之后暂存区清空
  git push -u origin master
将分支上的修改更新到github上
  撤回修改   git log 查看提交记录，获取commit id
  git reset &amp;ndash; 文件名 或者 commitId
使用当前分支上的修改覆盖暂存区，用来撤销最后一次 git add files
  git checkout &amp;ndash; 文件名</description>
    </item>
    
    <item>
      <title>Java List Map</title>
      <link>http://nixum.cc/p/java-list-map/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-list-map/</guid>
      <description>[TOC]
以下笔记如没指定版本，都是基于JDK1.8
Collection  javaCollection类图简版 
Set HashSet 1.基本   底层是HashMap，因此初始容量，默认负载因子、扩容倍数这些都和HashMap一样
  由于HashSet只需要key，因此value统一使用静态不可变的Object对象来装，即所有key共享这一个对象
  1 2  private transient HashMap&amp;lt;E,Object&amp;gt; map; private static final Object PRESENT = new Object();    HashSet允许存入null 不是线程安全的 不保证插入元素的顺序  List ArrayList 1.基本   底层：Object数组
  默认大小：10 （调用空参构造方法时）
最大是Integer.MAX_VALUE - 8（2^31 - 1，一些虚拟器需要在数组前加个头标签，所以减去 8 ）
调用此构造方法时，
1  public ArrayList(Collection&amp;lt;? extends E&amp;gt; c)   其中要注意的是，里面有这样一句话
1 2 3  // c.</description>
    </item>
    
    <item>
      <title>Java SE</title>
      <link>http://nixum.cc/p/java-se/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-se/</guid>
      <description>[TOC]
一、面向对象 面向对象的特征： 抽象(注意与当前目标有关的，选择一部分，暂时不用部分细节，分为过程抽象、数据抽象) 继承：联结类的层次模型、允许和鼓励类的重用，派生类可以从它的基类那里继承方法和实例变量，进行修改和新增使其更适合 封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面，这些对象通过一个受保护的接口访问其他对象 多态：允许不同类的对象对同一消息作出响应，包括参数化多态性和包含多态性，灵活、抽象、行为共享、代码共享，解决程序函数同名问题
二、基础类型及其包装类型    基本类型 boolean byte char short int float long double     包装类型 Boolean Byte Character Short Integer Float Long Double   位数 1 8 16 16 32 32 64 64   字节数  1 2 2 4 4 8 8      字符集
unicode是字符集，一种标准，UTF-8、UTF-16、GBK之类的是编码方式，是字符集的具体实现
UTF-16：定长,固定2字节， UTF-8：变长,中文占3字节,英文占1字节
char可以保存一个中文字符
java中采用unicode编码，无论中文、英文都是占2个字节
java虚拟机中使用UTF-16编码方式
java的字节码文件(.class)文件采用的是UTF-8编码，但是在java 运行时会使用UTF-16编码。
参考Java中的UTF-8、UTF-16编码字符所占字节数</description>
    </item>
    
    <item>
      <title>SpringMVC</title>
      <link>http://nixum.cc/p/springmvc/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/springmvc/</guid>
      <description>SpringMVC工作原理 SpringMVC工作原理详解
流程图看链接里的即可
简单来说各个组件的作用
 前端控制器DispatcherServlet：请求的入口，可以看成是中央处理器、转发器，负责调度其他组件，接收请求，完成响应 处理器映射器HandlerMapping：根据请求的url查找Handler，找到url对应的controller类，返回一条执行链，其中就包含拦截器和处理器（具体的controller类）；有配置文件方式，实现接口方式，注解方式等方式实现映射 处理器适配器HandlerAdapter：HandlerMapping找到对应的controller类后，再根据url找到对应的执行方法 处理器Handler：具体的处理方法，也就是我们所写具体的Controller类 视图解析器View resolver：根据逻辑View名称，找到对应的View，根据处理器返回的ModelAndView，将数据渲染到View上 视图View：例如jsp，freemarker之类的视图模板  拦截器在什么时候执行？
拦截器，是属于HandlerMapping级别的，可以有多个HandlerMapping ，每个HandlerMapping可以有自己的拦截器，拦截器可以设置优先级。一个请求交给一个HandlerMapping时，这个HandlerMapping先找有没有处理器来处理这个请求，如何找到了，就执行拦截器，执行完拦截后，交给目标处理器。如果没有找到处理器，那么这个拦截器就不会被执行。
实现HandlerInterceptor接口或者继承HandlerInterceptor，重写boolean preHandle()、void postHandle()、void afterCompletion()方法
  preHandle() 方法：该方法会在控制器方法前执行，其返回值表示是否中断后续操作。
当其返回值为true时，表示继续向下执行；当其返回值为false时，会中断后续的所有操作（包括调用下一个拦截器和控制器类中的方法执行等）。
  postHandle()方法：该方法会在控制器方法调用之后，且解析视图之前执行。可以通过此方法对请求域中的模型和视图做出进一步的修改。
  afterCompletion()方法：该方法会在整个请求完成，即视图渲染结束之后执行。可以通过此方法实现一些资源清理、记录日志信息等工作。
  Spring Security 简单工作流程
请求(包含用户名，密码之类)——&amp;gt;登陆信息封装成一个Authentication对象——&amp;gt;AuthenticationManager，调用authenticate ()方法处理——&amp;gt;该方法会将对象传递给一系列AuthenticationAdapter（一系列Filter），每一个AuthenticationAdapter会调用它们配置的UserDetailsService处理</description>
    </item>
    
    <item>
      <title>MyBatis</title>
      <link>http://nixum.cc/p/mybatis/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mybatis/</guid>
      <description>[TOC]
ORM 普通JDBC使用sql的prepareStatement + sql + 占位符 + 参数的方式执行sql语句
ORM其实就是在先编写类与数据库表字段的映射，可以是xml配置，也可以是注解配置，之后再使用JDBC执行sql时，通过对类的反射获得其属性的值和对应的字段名，拼接sql+占位符+属性值，执行sql语句
MyBatis #{}和${}区别
#{}：预编译，底层是PrepareStatement ，可防止SQL注入
${}：参数替换，不能防止SQL注入
dao接口与mapper的映射  通过动态代理实现 实际上XML在定义Mapper的时候就相当于在编写dao类了，dao接口类相当于编写调用入口 XML中的配置信息会被存放在Configuration类中，SqlSessionFactoryBuilder会读取Configuration类中的信息创建SqlSessionFactory，之后由SqlSessionFactory创建sqlSession 在启动时先扫描并加载所有定义Mapper的XML，解析XML，根据XML中的namespace找到对应的接口，为这些接口生成对应的代理工厂MapperProxyFactory。 sqlSession.getMapper时，会通过传入的类/接口名（即被代理类）找到对应的MapperProxyFactory，生成代理类MapperProxy，并注入sqlSession，MapperProxy实现InvocationHandler接口进行代理，通过MapperMethod执行SQL，MapperMethod使用注入的sqlSession和解析XML中配置的SQL语句得到的参数，调用对应的executor执行SQL  缓存  一级缓存的作用域是同一个SqlSession，在同一个sqlSession中两次执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。当一个sqlSession结束后该sqlSession中的一级缓存也就不存在了。Mybatis默认开启一级缓存。 二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession去操作数据库得到数据会存在二级缓存区域，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。不同的sqlSession两次执行相同namespace下的sql语句且向sql中传递参数也相同即最终执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。Mybatis默认没有开启二级缓存需要在setting全局参数中配置开启二级缓存  参考 MyBatis的通俗理解：SqlSession.getMapper()源码分析</description>
    </item>
    
    <item>
      <title>README</title>
      <link>http://nixum.cc/p/readme/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/readme/</guid>
      <description>为了更好的阅读体验，可前往 个人bolg、gitbook
目录 Java  Java SE JUC Java IO JVM  Go  Go SE GO 并发  框架  Spring SpringMVC MyBatis  数据存储  MySQL MongoDB Redis  微服务与云原生  Kubernetes 容器 etcd 与 ZooKeeper 微服务 分布式相关 RPC与异步设计 其他  消息队列  消息队列基本原理  计算机网络  网络  操作系统  操作系统  设计模式  设计模式  工具  git UML图  </description>
    </item>
    
  </channel>
</rss>
