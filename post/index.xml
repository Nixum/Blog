<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nixum Blog</title>
    <link>http://nixum.cc/post/</link>
    <description>Recent content in Posts on Nixum Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="http://nixum.cc/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>mongoDB</title>
      <link>http://nixum.cc/p/mongodb/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mongodb/</guid>
      <description>[TOC]
特点  分布式数据库，Json数据模型，面向对象数据模型，不强制表的scheme 当应用场景不清晰时，可以直接以对象模型直接存储，无需关心字段，表结构灵活，动态增加新字段 不用太过关注表间的关系，可直接嵌套存储，将多种关系存储在同一张表上，同时也加快查表，因为它可以减少磁盘定位次数，如果是关系型数据库，同时查多张表就需要定位多次 原生支持高可用，一般的部署方式是部署三个节点replica set，最多50个；多replica set可以实现自恢复（当主节点挂点后会选出从节点），异地容灾，数据库滚动更新 原生支持横向扩展，通过水平扩展分片实现，外部并不感知有多少个分片，只会当成一个分片使用 支持字段级加密，针对隐私数据，比如身份证、电话等，在入库时可以进行加密，查询时解密 支持地理位置经纬度查询 强大的聚合查询，适合报表、时序数据  NoSQL语句 客户端使用驱动时连接的执行流程
 客户端执行流程 
数据库端执行流程
 数据库端执行流程 
要获取ticket是因为MongoDB默认存储引擎wiredtiger的机制，ticket代表着系统资源的数量，ticket数量有限，读写操作都需要先获得ticket才可以进行下一步操作，机制类似信号量。
连接 连接mongoDB语句，当有多节点或多分片时，连接也要写上，mongodb://节点1的host:port, 节点2的host:port,.../databaseName?[options: maxPoolSize(java默认是100), maxWaitTime(查询的最大等待事件), writeConcern, readConcern]
mongoDB驱动里已提供负载均衡，多节点探测
聚合 作用相当与group by，可作用与多个collection，可进行查询和计算。Mongo的聚合操作发生在pipeline中，由多个stage组成，有点像责任链，通过多个state来过滤，聚合数据，每一个{}代表一个state
demo
MySQL中的SELECTdepartment,count(null)asemp_QTYFROMUserWHEREgender=&amp;#39;female&amp;#39;GROUPBYdepartmentHAVINGcount(*)&amp;lt;10等价于mongo中的db.user.aggregate([{$match:{gender:&amp;#39;female&amp;#39;}},{$group:{_id:&amp;#39;$DEPARTMENT&amp;#39;,emp_qty:{$sum:1}}},{$match:{emp_qty:{$lt:10}}}])几个比较特别的运算符
$unwind：将查询到的数组展开
$grouphLookup：图搜索
$facet/$bucket: 分面搜索，根据不同范围条件，多个维度一次性进行分组输出
优化  查询时，尽量使用索引，为经常做查询的条件添加索引 查询时，只查询需要的字段，而不是查询全部，减少网络资源的浪费 更新时，只更新必要的字段，而不是每次更新都把整个json文档发送过去，减少网络资源的浪费 插入时，尽可能直接批量插入，而不是一条一条插 通过mongodb提供的TTL索引，可以实现过期自删数据 建表时，文档嵌套不超过3层 尽量少用count()来计算总页数，而是使用limit 尽量少用skip/limit形式分页，而是通过id来定位起始的位置，这点跟aws dynamoDB很像，不过至少有提供这种功能 尽量少用事务，跨分片事务，避免过大事务，控制更新的文档(行)数量 使用aggregate时，前一个stage计算得到的数据会传递到下个stage，如果前一个stage没有该数据，则下一个stage无法获取到（尽管表中有该字段） 使用aggregate时，pipeline最开始时的match sort可以使用到索引，一旦发生过project投射，group分组，lookup表关联，unwind打散等操作后，则无法使用索引。  分析  在查询语句中使用explain()方法分析查询语句，有三种分析模式，通过传参的方式使用，比如：db.getCollection(&amp;quot;order&amp;quot;).explain(&#39;executionStats&#39;).find({条件})  queryPlanner：默认，只会输出被查询优化器选择出来的查询计划winningPlane executionStats：除了输出被查询优化器选择出来的查询计划winningPlane，并执行语句（如果是写操作，不会真正操作数据库），给出分析结果，比如扫描的行数，使用什么索引，耗时，返回的条数等 allPlansExecution：列出所有可能的查询计划并执行，给出所有方案的结果，mongo支持这种分析模式，但aws的documentDB不支持    # 常见的stage枚举： COLLSCAN：全表扫描 IXSCAN：索引扫描 FETCH：根据前面扫描到的位置抓取完整文档，相当于回表 IDHACK：针对_id进行查询 SHARD_MERGE 合并分片中结果 SHARDING_FILTER 分片中过滤掉孤立文档 SORT：进行内存排序，最终返回结果 SORT_KEY_GENERATOR：获取每一个文档排序所用的键值 LIMIT：使用limit限制返回数 SKIP：使用skip进行跳过 IDHACK：针对_id进行查询 COUNTSCAN：count不使用用Index进行count时的stage返回 COUNT_SCAN：count使用了Index进行count时的stage返回 TEXT：使用全文索引进行查询时候的stage返回 SUBPLA：未使用到索引的$or查询的stage返回 PROJECTION：限定返回字段时候stage的返回 # 一个executionStats例子 { &amp;quot;queryPlanner&amp;quot; : { &amp;quot;plannerVersion&amp;quot; : 1.</description>
    </item>
    
    <item>
      <title>容器</title>
      <link>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</guid>
      <description>[TOC]
底层原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个边界。
Namespace - 隔离 进程只能看到被规定的视图，即 隔离，比如通过docker启动一个/bin/sh，再在容器里通过ps命令查看该/bin/sh进程的pid，会发现它的pid是1，但是实际上它在外部的宿主机里的pid是10，使得让在容器里运行的进程以为自己就在一个独立的空间里，实际上只是进行了逻辑的划分，本质还是依赖宿主机。
作用：在同一台宿主机上运行多个用户的容器，充分利用系统资源；不同用户之间不能访问对方的资源，保证安全。
常见的Namespace类型有：
 PID Namespace：隔离不同容器的进程 Network Namespace：隔离不同容器间的网络 Mount Namespace：隔离不同容器间的文件系统  与虚拟化的区别：虚拟化是在操作系统和硬件上进行隔离，虚拟机上的应用需要经过虚拟机在经过宿主机，有两个内核，本身就有消耗，而容器化后的应用仅仅只是宿主机上的进程而已，只用到宿主机一个内核
因为namespace隔离的并不彻底，由于内核共享，容器化应用仍然可以把宿主机的所有资源都吃掉，有些资源不同通过namespace隔离，比如修改了容器上的时间，宿主机上的时间也会被改变，因此需要Cgroups
Cgroups - 资源限制 是用来制造约束的主要手段，即对进程设置资源能够使用的上限，如CPU、内存、IO设备的流量等
比如，限定容器只能使用宿主机20%的CPU
docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash  Cgroups 通过不同的子系统限制了不同的资源，每个子系统限制一种资源。每个子系统限制资源的方式都是类似的，就是把相关的一组进程分配到一个控制组里，然后通过树结构进行管理，每个控制组都设有自己的资源控制参数。
 常见的Cgroups子系统
 CPU 子系统，用来限制一个控制组（一组进程，你可以理解为一个容器里所有的进程）可使用的最大 CPU。 memory 子系统，用来限制一个控制组最大的内存使用量。 pids 子系统，用来限制一个控制组里最多可以运行多少个进程。 cpuset 子系统， 这个子系统来限制一个控制组里的进程可以在哪几个物理 CPU 上运行。  Cgroups 有 v1 和 v2 两个版本，v1中每个进程在各个Cgroups子系统中独立配置，可以属于不同的group，比较灵活但因为每个子系统都是独立的，会导致对同一进程的资源协调困难，比如同一容器配置了Memory Cgroup和Blkio Cgroup，但是它们间无法相互协作。
v2针对此做了改进，使各个子系统可以协调统一管理资源。
Mount Namespace与rootfs(根文件系统) 挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，即容器镜像，也是容器的根文件系统。Mount Namespace保证每个容器都有自己独立的文件目录结构。
镜像可以理解为是容器的文件系统（一个操作系统的所有文件和目录），它是只读的，挂载在宿主机的一个目录上。同一台机器上的所有容器，都共享宿主机操作系统的内核，如果容器内应用修改了内核参数，会影响到所有依赖的应用。而虚拟机则都是独立的内核和文件系统，共享宿主机的硬件资源。
 上面的读写层通常也称为容器层，下面的只读层称为镜像层，所有的增删查改操作都只会作用在容器层，相同的文件上层会覆盖掉下层。知道这一点，就不难理解镜像文件的修改，比如修改一个文件的时候，首先会从上到下查找有没有这个文件，找到，就复制到容器层中，修改，修改的结果就会作用到下层的文件，这种方式也被称为copy-on-write。
 注意点 容器是“单进程模型”，单进程模型并不是指容器只能运行一个进程，而是指容器没有管理多个进程的能力，它只能管理一个进程，即如果在容器里启动了一个Web 应用和一个nginx，如果nginx挂了，你是不知道的。</description>
    </item>
    
    <item>
      <title>微服务</title>
      <link>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>[TOC]
对微服务的理解 http://dockone.io/article/3687
限流 下面的方案都是单机版本的，在分布式环境下可以把限流的实例放到Redis里，或者直接使用Lua脚本实现，保证并发安全。
固定窗口 规定单位时间内可访问的次数，比如规定接口一分钟内只能访问10次，以第一次请求为起始，计数1，一分钟内计数超过10后，后续的请求直接拒绝，只能等到这一分钟结束后，重置计数，重新开始计数。
但是这样有个问题，如果在大部分请求集中在第一个窗口的后10s内，和第二个窗口的前10s内，虽然他们都符合限流策略，但是在临界的20s内，请求还是有可能压垮系统。
算法Demo：
type fixWinLimiter struct { lock *sync.Mutex maxLimitCount int64 // 最大限制数 	currentCount int64 // 当前计数 	fixInterval int64 // 为了简化，单位设置为秒 	lastReqStartAt int64 // 秒级时间戳 } func NewFixWinLimit(fixInterval int64, maxLimitCount int64) *fixWinLimiter { return &amp;amp;fixWinLimiter{ lock: new(sync.Mutex), maxLimitCount: maxLimitCount, fixInterval: fixInterval, } } func (f *fixWinLimiter) IsPass() bool { f.lock.Lock() defer f.lock.Unlock() now := time.Now().Unix() if now - f.lastReqStartAt &amp;gt; f.fixInterval { f.</description>
    </item>
    
    <item>
      <title>操作系统</title>
      <link>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>[TOC]
内核 PC机启动流程 以Ubuntu Linux + GRUB引导程序为例：
PC机加电后，加载BIOS固件， 触发PC机BIOS固件发送指令 检测和初始化CPU、内存及主板平台，加载引导设备(比如硬盘)中的第一个扇区数据到0x7c00地址开始的内存空间，再接着跳转到0x7c00处执行指令，加载GRUB引导程序，加载硬盘分区中的OS文件，启动操作系统。
内核结构分类 内核：计算机资源的管理者。计算资源分为硬件资源和软件资源
  硬件资源：CPU、内存、硬盘、网卡、显卡、IO设备、总线，他们之间通过总线进行联系；
  软件资源：对上述各种硬件资源的管理程序、设备的驱动程序
  宏内核结构 - 类似单体服务 将上述所有软件资源进行整合，链接在一起，形成一个大的可执行程序，控制所有硬件资源。这个大程序会在处理器的特权模式下运行，对外提供系统调用函数，供其他程序、进程调用。
当应用层有程序要调用进行内存分配时，就会调用宏内核进行内存分配
 应用程序调用内核内存分配API函数 处理器切换到特权模式，开始运行内核代码 内核的内存管理代码按照特定的算法，分配内存 内存分配函数把分配的内存块的首地址返回给应用程序 应用程序接收到返回后，处理器开始运行用户模式下的应用程序，应用程序使用得到的内存首地址，开始使用这块内存  优点：由于所有硬件管理程序都整合在一起，相互调用时性能极高
缺点：所有硬件管理程序都整合在一起，没有模块化，扩展性差，移植性差，牵一发而动全身，每次修改都需要重新安装，其中一个模块有问题就会影响其他模块。
Linux就属于宏内核
 Linux 的基本思想是一切都是文件：每个文件都有确定的用途，包括用户数据、命令、配置参数、硬件设备等对于操作系统内核而言，都被视为各种类型的文件。Linux 支持多用户，各个用户对于自己的文件有自己特殊的权利，保证了各用户之间互不影响。多任务则是现代操作系统最重要的一个特点，Linux 可以使多个程序同时并独立地运行。
 第一次访问 
Linux使用宏内核架构，主要分为上述五大模块，模块间的通信通过函数调用，函数间的调用没有层次关系，所以函数的调用路径纵横交错，如果有函数出问题，那就会影响到调用它的模块，存在安全隐患，但优点是存内核调用，性能极高
Linux高清全结构图：https://makelinux.github.io/kernel/map/
 微内核结构 - 类似微服务 内核仅处理进程调度、中断、内存空间映射、进程间通信等，控制硬件资源的软件资源，转成一个个服务进程，比如进程管理、内存管理、设备管理、文件管理等，和用户进程一样，只是它们提供了宏内核的那些功能。
微内核内，进程间通过消息进行通信，应用程序每次要申请资源都需要发送消息到微内核，微内核再把这条消息转发给相关服务进程，直到完成这次调用。
当应用层有程序要调用进行内存分配时
 应用程序发送内存分配的消息（发送消息这个函数由微内核提供） 处理器切换到特权模式，执行内核代码 微内核让当前进程停止运行，并根据消息包中的数据，推送给对应的消息接收者，比如这里是内存管理服务进程。 内存管理服务进程收到消息，分配一块内存 内存管理服务进程，处理完成后，通过消息的形式返回分配内存块的地址给内核，然后继续等待下一条消息。 微内核把包含内存地址的消息返回发送给内存分配消息的应用程序 处理器开始运行用户模式下的应用程序，应用程序收到这条消息，得到内存首地址，开始使用这块内存。  优点：系统结构清晰，移植性、伸缩性、扩展性强，微内核代码少，容易替换，各种系统服务进程可随时替换
缺点：进程间消息依赖微内核进行消息传递，会频繁进行服务进程切换，模式切换，导致性能较差。
分离硬件的相关性 分离硬件的相关性其实就是屏蔽底层硬件操作细节，形成一个独立的软件抽象层，对外提供接口，方便应用层接入。
是内核设计的一种指导思想，所以在设计操作系统内核的时候，就可以分为
 内核接口层：向应用层提供系统接口函数； 内核功能层：系统函数的主要实现，实现进程管理、内存管理、中断管理、设备管理、驱动、文件系统等； 内核硬件层：对硬件资源的操作，比如初始化CPU、内存、中断控制、其他IO设备  混合内核 混合内核在微内核的基础上进行改进，层次分明，动态加载模块到内核，兼具宏内核和微内核的优点。</description>
    </item>
    
    <item>
      <title>go并发</title>
      <link>http://nixum.cc/p/go%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go%E5%B9%B6%E5%8F%91/</guid>
      <description>[TOC]
内存模型 这里的内存模型不是指内存分配、整理回收的规范，而是在并发环境下多goroutine读取共享变量时变量的可见性条件。
由于不同的架构和不同的编译器优化，会发生指令重排，导致程序运行时不一定会按照代码的顺序执行，因此两个goroutine在处理共享变量时，能够看到其他goroutine对这个变量进行的写结果。
happens-before：程序的执行顺序和代码的顺序一样，就算真的发生了重排，从行为上也能保证和代码的指定顺序一样。
Go不像Java有volatile关键字实现CPU屏障来保证指令不重排，而是使用不同架构的内存屏障指令来实现同一的并发原语。
Go只保证goroutine内部重排对读写顺序没有影响，如果存在共享变量的访问，则影响另一个goroutine。因此当有多个goroutine对共享变量的操作时，需要保证对该共享变量操作的happens-before顺序。
证heppen before的手段   init函数：同一个包下可以有多个init函数，多个签名相同的init函数；main函数一定在导入的包的init函数执行之后执行；当有多个init函数时，从main文件出发，递归找到对应的包 - 包内文件名顺序 - 一个文件内init函数顺序执行init函数。
  全局变量：包级别的变量在同一个文件中是按照声明顺序逐个初始化的；当该变量在初始化时依赖其它的变量时，则会先初始化该依赖的变量。同一个包下的多个文件，会按照文件名的排列顺序进行初始化。
init函数也是如此，当init函数引用了全局变量a，运行main函数时，肯定是先初始化a，再执行init函数。
当init函数和全局变量无引用关系时，先初始化全局变量，再执行init函数
  var ( a = c + b // == 9  b = f() // == 4  c = f() // == 5  d = 3 // 全部初始化完成后 == 5 ) func f() int { d++ return d } --- func init() { a += 1 fmt.</description>
    </item>
    
    <item>
      <title>go</title>
      <link>http://nixum.cc/p/go/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go/</guid>
      <description>[TOC]
以下基于go.1.14
函数内联优化 函数内联优化：在A函数中调用了B函数，内联后，B函数的代码直接在A函数内原地展开，代替这个函数实现，当有多次调用时，就会多次展开
go在编译时会自动判断函数是否可以内联，当函数内包含以下内容时不会被内联：闭包调用，select，for，defer，go关键字创建的协程等。
内联的好处：因为函数调用被内联了，可以减少栈帧的创建，减少读写寄存器的读取，减少参数和函数的拷贝，提升性能
缺点：堆栈panic显示的行数可能不准确、增加编译出来的包的大小
编译时使用go build -gcflags=&amp;quot;-m -m&amp;quot; main.go可以知道编译器的内联优化策略，
go编译时默认会使用内联优化，使用go build --gcflags=&amp;quot;-l&amp;quot; main.go可禁掉全局内联，如果传递两个或以上-l，则会打开内联
数组  声明时必须指定固定长度，因为编译时需要知道数组长度以便分配内存，如var arr1 [5]int，或者var arr2 = [5]int{1,2,3}, 其余数字为0 数组长度最大是2Gb 当数组类型是整形时，所有元素都会被自动初始化为0，即声明完数组，数组会被设置类型的默认值 可以使用new()来创建，如var arr3 = new([3]int)，arr3的类型是*[3]int，arr1、arr2的类型是[5]int 函数的参数可以是[5]int, 表明入参是数组，如果是[]int，表明入参是slice。类型[3]int和[5]int是两种不同的类型。 数组是值类型，赋值和传参会进行拷贝，函数内部的修改不会影响原始数组。 如果数组中的元素个数小于或等于4个，所有变量会直接在栈上初始化；当数组元素大于4个，变量就会在静态存储区初始化然后拷贝到栈上。  切片Slice 数据结构 slice本质是一个结构体，所以它是值类型是不难理解的，它仅仅只是对数组的一种包装，且该结构体不包含任何函数，任何对slice的处理都是go的内置函数来处理的。
type Slice struct { ptr unsafe.Pointer // 指向数组的指针 	len int // 切片长度 	cap int // 切片容量 } 基本   创建时无需指定长度，如 slice1 := []int{1,2,3}, 此时长度和容量均为3
  从数组上截取arr1 := [5]int; var slice2 []int = arr1[1:3], 此时长度2，容量5，且对slice2的修改会影响arr1。</description>
    </item>
    
    <item>
      <title>etcd和ZooKeeper</title>
      <link>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</guid>
      <description>[TOC]
ZooKeeper ZooKeeper保证的是CP，不保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。
使用场景  集群管理，监控节点存活状态 主节点选举，当服务以master-salve模式进行部署，当主节点挂掉后选出新的主节点 服务发现 分布式锁，提供独占锁、共享锁 分布式自增id 搭配Kafka、dubbo等使用  特点  顺序一致性：同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。  数据模型 类似文件系统，根节点为 / ，每创建一个节点会从根节点开始挂，树形结构，每个数据节点称为znode，可以存储数据，每个znode还有自己所属的节点类型和节点状态
  持久节点：一旦创建就一直存在，直到将其删除。 持久顺序节点：一个父节点可以为其子节点 维护一个创建的先后顺序 ，这个顺序体现在 节点名称 上，是节点名称后自动添加一个由 10 位数字组成的数字串，从 0 开始计数。 临时节点：临时节点的生命周期是与 客户端会话 绑定的，会话消失则节点消失 。临时节点 只能做叶子节点 ，不能创建子节点。 临时顺序节点：父节点可以创建一个维持了顺序的临时节点(和前面的持久顺序性节点一样)。   ZAB协议 通过ZAB协议保证注册到ZooKeeper上的主从节点状态同步，该协议有两种模式
  崩溃恢复
当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。
  消息广播
当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案（超过半数同意）来进行事务请求处理。</description>
    </item>
    
    <item>
      <title>Java IO</title>
      <link>http://nixum.cc/p/java-io/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-io/</guid>
      <description>[TOC]
BIO 特点
 BIO是同步阻塞的，以流的形式处理，基于字节流和字符流 每个请求都需要创建独立的线程，处理Read和Write 并发数较大时，就算是使用了线程池，也需要创建大量的线程来处理 连接建立后，如果处理线程被读操作阻塞了，那就阻塞了，只能等到读完才能进行其他操作  以基于TCP协议的Socket，编写服务端Demo
package com.nixum.bio; import java.io.InputStream; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; import java.util.Date; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class BIOServer { public static void main(String[] args) throws Exception { ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); //创建ServerSocket  ServerSocket serverSocket = new ServerSocket(8080); while (true) { // 主线程负责处理监听  final Socket socket = serverSocket.accept(); // 创建线程处理请求  newCachedThreadPool.execute(() -&amp;gt; { handler(socket); }); } } public static void handler(Socket socket) { try { byte[] bytes = new byte[1024]; //通过socket获取输入流  InputStream inputStream = socket.</description>
    </item>
    
    <item>
      <title>其他</title>
      <link>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</guid>
      <description>[TOC]
Quartz   分为三个部分：e
 Job&amp;amp;Detial(任务)：定时任务的执行方法，与Trigger配套的 Trigger(触发器)：规定什么时候触发，与Job&amp;amp;Detail配套的 Scheduler(调度器)：单例，把Trigger丢里面由调度器调度，只需要一个Scheduler，配置不同的Trigger；可以理解成类似线程池的东西    原理：ScheduledThreadPoolExecutor线程池 + 通过Object类的wait()和notify()或者Condition类的await()\signal()进行等待和唤醒、锁保证线程安全 来进行调度
Scheduler有两个调度线程：regular Scheduler Thread（执行常规调度）和Misfire Scheduler Thread（执行错失的任务），Regular Thread 轮询所有Trigger，如果有将要触发的Trigger（用wait和notifyAll实现），则从任务线程池中获取一个空闲线程，然后执行与改Trigger关联的job；Misfire Thraed则是扫描所有的trigger，查看是否有错失的，如果有的话，根据一定的策略进行处理
  默认是并发的，即如果当前任务没有完成，会自动开一个任务执行
  注意在分布式集群的情况下，多台机子有相同的定时任务，会出错，此时通过共享数据库的方式实现
Quartz的解决方案：
quartz集群分为水平集群和垂直集群，水平集群即将定时任务节点部署在不同的服务器，其最大的问题就是时钟同步问题，若时钟不能同步，则会导致集群中各个节点状态紊乱，造成不可预知的后果；垂直集群则是集群各节点部署在同一台服务器，时钟同步自然不是问题，但存在单点故障问题，服务器宕机会严重影响服务的可用性
在各个节点会上报任务，存到数据库中，执行时会从数据库中取出触发器来执行，如果触发器的名称和执行时间相同，则只有一个节点去执行此任务。
如果此节点执行失败，则此任务则会被分派到另一节点执行，中途也会自动检查失效的定时调度，发现不成功的，其他节点立马接过来继续完成定时任务。Quartz有11个定时任务调度表
  参考
Quartz原理解密
深入解读Quartz的原理
Quartz 2.2 的实现原理和运行过程
其他定时器  Timer：这是java自带的java.util.Timer类，这个类允许你调度一个java.util.TimerTask任务。使用这种方式可以让你的程序按照某一个频度执行，但不能在指定时间运行。一般用的较少。单线程，任务一多会阻塞；一个任务出异常其他任务都受影响；受系统时间影响 ScheduledExecutorService：也jdk自带的一个类；是基于线程池设计的定时任务类,每个调度任务都会分配到线程池中的一个线程去执行,也就是说,任务是并发执行,互不影响。线程池+延时队列DelayedQueue(数组、最小堆, 最近要执行的任务放在堆顶) 实现，如果堆顶任务时间未到就阻塞（通过自旋+condition.await\signal实现）。不受系统时间影响 Spring 中的 @Schedule 注解  参考：Java 定时任务实现原理详解
Java优先级队列DelayedWorkQueue原理分析
CORS 浏览器的同源政策的同源指的是：协议相同、域名相同、端口相同，如果非同源，有三种行为会受到限制：Cookie、LocalStorage和IndexDB无法读取；DOM无法获得、AJAX请求不能发送。
前后端分离的场景下，由于浏览器的同源策略，导致浏览器内的请求不同的源的后端是会失败，常见的解决跨域方法是使用CORS，现在常见的web框架都支持CORS，开启即可。
解决跨域的方法除了CORS，还有jsonp，不过已经很少使用了，jsonp本质是利用浏览器允许加载不同源的js文件即标签等，将跨域请求标签里，返回一段可执行的js代码，其中包含了请求结果，通常是json格式，前端通过返回的js代码执行回调获取结果。
详情见 跨域资源共享 CORS 详解
对于跨域产生的问题，如CSRF跨域请求攻击的解决方案，可参考：美团:如何防止csrf
session和cookie   首先Http是无状态的，因此需要通过session、cookie来达到记录用户状态的目的。
  传统的session、cookie：session存用户信息，保存在服务端中，cookie里存session对应的sessionId，保存在客户端中，用于找到对应的session，每次请求都会带上该cookie来表示此用户。</description>
    </item>
    
    <item>
      <title>消息队列</title>
      <link>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      <description>[TOC]
使用场景  秒杀系统，一般秒杀系统处理包含几个步骤：风险控制、库存锁定、生成订单、短信通知、更新统计数据灯，而决定秒杀是否成功只在前两个步骤，后续的操作就可以通过消息队列异步处理完成，加快整个流程的处理，减少等待时间，提升并发量。 隔离网关和后端服务，实现流量控制，保护后端服务，但会增加系统调用链，导致总体响应变长，异步增加系统复杂性。 令牌桶，目的也是进行流量控制。 服务解耦，数据同步，比如订单系统在订单状态发生变化时发出消息通知，其他服务订阅后做相应处理。 连接流计算任务和数据，比如集群日志处理，大数据统计 将消息广播给其他接收者  好处 流量削峰和流量控制、异步处理、解耦、广播、最终一致性
缺点 可用性降低、复杂度提高、一致性问题、消息延迟
常见消息队列    特性 ActiveMQ RabbitMQ RocketMQ Kafaka     单机吞吐量 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ 10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景   topic数量对吞吐量的影响  使用队列模型，通过Exchange模块实现发布-订阅模型，Exchange位于生产者和队列之间，由Exchange决定将详细投递到哪个队列。 topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源   可用性 高，基于主从架构实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用   消息可靠性 有较低的概率丢失数据  经过参数优化配置，可以做到0丢失 经过参数优化配置，消息可以做到0丢失   时效性 ms级 微秒级，这是rabbitmq的一大特点，延迟是最低的 ms级 延迟在ms级以内   功能支持 MQ领域的功能极其完备 基于erlang开发，所以并发能力很强，性能极其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准   优劣势总结 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。偶尔会有较低概率丢失消息，而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.</description>
    </item>
    
    <item>
      <title>设计模式</title>
      <link>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      <description>[TOC]
只记录常用设计模式
设计模式六大原则  单一职责原则(SRP)：一个类只负责一个功能领域中的相应职责，就一个类而言，应该只有一个引起它变化的原因。 开闭原则(OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 里氏代换原则(LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 依赖倒转原则(DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。如 控制反转和依赖注入 接口隔离原则(ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 迪米特法则(LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。  常见设计模式 创建型模式是将创建和使用代码解耦
结构型模式是将不同功能代码解耦
行为型模式是将不同的行为代码解耦
创建型 单例模式 数据在应用上只保持一份，解决资源访问冲突的问题，就可以使用单例模式
/** 1. * 懒汉模式,线程不安全，只有在调用方法的时候才实例化,好处是没用到该类时就不实例化，节约资源 */ class LazyInstance { private static LazyInstance singleton; private LazyInstance() { // if (singleton != null) // throw new RuntimeException();  } /** 1.1 * 想要线程安全只需在方法上加上synchronized关键字，缺点是，多线程访问时锁的操作耗时 */ public static LazyInstance getInstance() { if (singleton == null) { singleton = new LazyInstance(); } return singleton; } } /** 2.</description>
    </item>
    
    <item>
      <title>RPC与异步设计</title>
      <link>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</guid>
      <description>[TOC]
RPC  
一个RPC框架的基本实现，高性能网络传输、序列化和反序列化、服务注册和发现，如果是实现客户端级别的服务注册和发现，还可以在SDK中提供容错、负载均衡、熔断、降级等功能。
客户端发起RPC调用，实际上是调用该RPC方法的桩，它和服务端提供的RPC方法有相同的方法签名，或者说实现了相同的接口，只是这个桩在客户端承担的是请求转发的功能，向客户端屏蔽调用细节（比如向发现与注册中心查询要请求的服务方的url），使其像在使用本地方法一样；服务端在收到请求后，由其RPC框架解析出服务名和请求参数，调用在RPC框架中注册的该接口的真正实现者，最后将结果返回给客户端。
一个简单的RPC实现可以由三部分组成：规定远程的接口和其实现，服务端提供接口注册和IO连接，客户端IO连接和接口代理
  首先是定义要提供的远程接口和其实现类
  服务端使用线程池处理IO，实现多路复用，使用socket去循环accept()，每个请求建立一个线程
线程里注册远程接口实例，使用InputStream接收客户端发送的参数，如接口的字节文件，判断是哪个接口，哪个方法，什么参数；接收后反射调用接口方法，将结果通过OutputStream发送回客户端
客户端在发送参数可以做一个封装，加入id，服务端处理得到结果后也加入此id，返回回去，表示此次调用完成
  客户端使用接口，动态代理的方式调用方法，在动态代理的实现里使用IO连接服务端，将远程接口字节码、方法参数这些东西做一个封装发送给服务端，等待返回结果，IO接收是阻塞的
  参考【Java】java实现的远程调用例子 rpc原理
RPC原理及RPC实例分析
异步通信 优点：解耦，减少服务间的依赖，获得更大的吞吐量，削峰，把抖动的吞吐量变得均匀。
缺点：业务处理变得复杂，比如引入新的中间件，意味着要维护多一套东西，有时可能还得保证消息顺序，失败重传，幂等等处理，比较麻烦；异步也导致了debug的时候比较麻烦；
定时轮询 发送方请求接收方进行业务处理，接收方先直接返回，之后接收方在自己处理，最后将结果保存起来，发送方定时轮询接收方，获取处理结果。
回调 发送方请求接收方进行业务处理时，带上发送方结果回调的url，接收方接收到请求后先立刻返回，之后接收方在自己处理，当处理结果出来时，调用发送方带过来的回调url，将处理结果发送给发送方。
同理在于服务内部的异步回调，也是如此，只是把url换成了callback方法，比如Java中的Future类+Callable类。
发布订阅 主要靠消息队列实现，不过比较适合发送方不太care处理结果的，如果care处理结果，可以再通过一条队列将结果传递下去，执行后面的处理。
事件驱动 + 状态机 可以依靠消息队列，本质还是发布订阅那一套，只是将触发的条件换成事件，消费者根据不同的事件触发不同的逻辑，然后再通过状态机保证处理事件顺序。
比较常见的场景是电商业务中围绕订单服务的一系列业务处理，比如订单创建完成后，订单服务发出订单创建的事件，对应库存服务，收到该事件，就会进行锁库操作等</description>
    </item>
    
    <item>
      <title>分布式相关</title>
      <link>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</guid>
      <description>[TOC]
分布式理论 一个分布式系统最多只能满足 C、A、P 这三项中的两项。
CAP理论 CAP特性
 C：Consistency，一致性，数据状态转化一致，写操作完成后的读操作，可以获取到最新的值 A：Availability，可用性，指的是服务一直可用，可以正常响应 P：Partition tolerance，分区容错，指的是当有节点故障不连通时，就会分区，但仍然能对外提供服务  矛盾在于这三个特性不能同时满足，比如
 当分布式集群内有两个主从服务发生网络故障，但此时服务仍然可以访问，此时具有分区容错性。
当对主服务对数据进行修改时，由于网络问题，无法同步到从服务，当访问到从服务时，无法获取到最新的值，此时满足可用性，但是无法满足一致性。
当主从服务间网络恢复，写操作的数据虽然能在服务间同步了，但还未同步完成，此时访问从服务无法获取最新值，此时满足了一致性，但是无法满足可用性。
简单概括，只要满足分区容错，就会设置复制集，复制集同时也保证了可用，但是复制集又会有数据同步，此时又有一致性问题
 所以，一般只会满足其中两个
 1、满足CA舍弃P，也就是满足一致性和可用性，舍弃容错性。但是这也就意味着你的系统不是分布式的了，因为涉及分布式的想法就是把功能分开，部署到不同的机器上。
2、满足CP舍弃A，也就是满足一致性和容错性，舍弃可用性。如果你的系统允许有段时间的访问失效等问题，这个是可以满足的。就好比多个人并发买票，后台网络出现故障，你买的时候系统就崩溃了。
3、满足AP舍弃C，也就是满足可用性和容错性，舍弃一致性。这也就是意味着你的系统在并发访问的时候可能会出现数据不一致的情况。
 所以为了分布式服务能正常使用，一般时会满足分区容错性和可用性，在一致性上不追求强一致性，而是一个逐渐一致的过程。
BASE理论 BASE理论是对CAP三者均衡的结果，基于CAP理论演化而来，通过牺牲强一致性来获得高可用。
 Basically Available（基本可用）: 允许暂时不可用，比如访问时可以等待返回，服务降级，保证核心可用等。 Soft state（软状态）: 允许系统存在中间状态，而该中间状态不会影响系统整体可用性，比如允许复制集副本间的数据存在延时，数据库的数据同步过程。 Eventually consistent（最终一致性）: 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。  与数据库ACID类似，只是强度减弱了
参考：CAP 定理的含义
关于可靠性、可用性、稳定性：   可靠性Reliability：不出事故，故障率低，关注的是系统无故障地持续运行的概率，比如
  MTBF（Mean Time Between Failure）：即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。MTBF越长表示可靠性越高，正确工作能力越强 。
  MTTR（Mean Time To Repair）：即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。MTTR越短表示易恢复性越好。
  MTTF（Mean Time To Failure）：即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。系统的可靠性越高，平均无故障时间越长。
  与可用性的关系：Availability = UpTime/(UpTime+DownTime) = MTBF / (MTBF + MTTR)</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>http://nixum.cc/p/redis/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/redis/</guid>
      <description>[TOC]
数据类型及结构 数据类型 String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet
String类型下还有一种扩展类型：Bitmap。原理：String类型会保存二进制字节数组，对于这个字节数组的每个bit来表示一个元素的二值状态。
此外还有扩展类型：HyperLogLog、Geo
底层数据结构  String：简单动态字符串(SDS) List：双向链表 + 压缩列表 Hash：哈希表 + 压缩列表 Set：整数数组+ 哈希表 ZSet：跳表 + 压缩列表  简单动态字符串(SDS) Redis的String类型底层有两种保存形式，当保存的是64位有符号整数时，String类型会保存为一个9字节的Long类型整数；当保存的数据包含字符时，String类型就会用简单动态字符串SDS。
简单动态字符串SDS由三个部分组成：
 buf：是字节数组，保存实际数据，结束标志位是&amp;quot;/0&amp;quot;。 len：表示buf已用长度，占4字节 alloc：表示buf的实际分配长度，一般大于len  此外，对于每种数据类型，Redis会使用RedisObject来记录一些元数据，比如最后以此访问时间，引用次数等，RedisObject包含了8个字节的元数据和一个8字节指针，指针指向具体的数据类型的实际数据所在。
对于String类型的RedisObject：
 当保存的是Long类型整数时，RedisObject中的指针直接就是整数数据，不用额外的指针指向整数； 当保存的是字符串时，如果字符串&amp;lt;=44字节，RedisObject中元数据，指针和SDS是一块连续的内存区域，避免内存碎片 当保存的是字符串时，如果字符串&amp;gt;44字节，RedisObject会给SDS分配独立的空间，并用指针指向SDS  ![Redis String RedisObject: 来自极客时间Redis核心技术与实战](https://github.com/Nixum/Java-Note/raw/master/picture/Redis String RedisObject.png)
当使用String类型时，且value的类型是String时，如果value的长度太小，可能会出现元数据的大小比数据本身的大小还大，造成额外的内存开销。如果能替换成Long类型，实际存储的大小会大大降低。
哈希表 但无论值是什么类型的，所有的键值对会保存在全局哈希表中，便于快速找到对应的Key，哈希桶只会保存键值对的指针。全局哈希表中的桶每个元素entry由三个8字节指针组成，分别为key、value、next，但实际会占32字节，因为内存分配库jemalloc会分配最接近24的2的幂次数，所以是32，以减少频繁的分配次数。
因此，即使Redis里存在大量数据，也不影响查找的速度，毕竟都是根据Key进行hash就能找到对应的Value，真正有影响的是哈希表的在解决哈希冲突和rehash时带来的阻塞。
Redis的哈希表使用拉链法解决哈希冲突。通过两个全局哈希表加快rehash的操作。
处理全局哈希表有这种操作，Hash的数据结构也是这样的操作，本质是一样的。
当Redis生产RDB和AOF重写时，哈希表不会进行rehash。
rehash触发条件 装载因子：哈希表中所有entry的个数除以哈希表的哈希桶个数。
  当装载因子&amp;gt;= 1，且哈希表被允许rehash，即此时没有进行RDB和AOF重写
  当装载因子&amp;gt;= 5，因为此时数据量已远远大于哈希桶的个数了，此时会立马进行rehash
  rehash过程   默认使用哈希表1，此时哈希表2还没有被分配空间
  当数据增多至需要rehash时，为哈希表2分配空间，大小会比哈希表1大，比如大两倍
  把哈希表1中的数据重新映射并拷贝到哈希表2中</description>
    </item>
    
    <item>
      <title>Kubernetes和Istio</title>
      <link>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</guid>
      <description>[TOC]
Kubernetes 基本  
容器的本质是进程，Kubernetes相当于操作系统，管理这些进程组。
 CNI：Container Network Interface，容器网络接口规范，如 Flannel、Calico、AWS VPC CNI kubelet：负责创建、管理各个节点上运行时的容器和Pod，这个交互依赖CRI的远程调用接口，通过Socket和容器运行时通信。 kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件 kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储，交互的接口是CNI和CSI CRI：Container Runtime Interface，容器运行时的各项核心操作的接口规范，是一组gRPC接口。包含两类服务，镜像服务和运行时服务。镜像服务提供下载、检查和删除镜像的RPC接口；运行时服务包含用于管理容器生命周期，与容器交互的调用的RPC接口（exec / attach / port-forward等）。dockershim、containerd、cri-o都是遵循CRI的容器运行时，称为高层级运行时。 CSI：Container Storage Interface，容器存储的接口规范，如PV、PVC OCI：Open Container Initiative，容器运行时和镜像操作规范，镜像规范规定高层级运行时会下载一个OCI镜像，并把它解压称OCI运行时文件系统包；运行时规范描述如何从OCI运行时文件系统包运行容器程序，并且定义其配置、运行环境和生命周期。定义新容器的namespaces、cgroups和根文件系统；它的一个参考实现是runC，称为底层级运行时。 CRD：Custom Resource Definition，自定义的资源对象，即yaml文件中的Kind，如Operator就是实现CRD的控制器，之后直接使用Operator创建的CRD声明对象即可使用 Master节点作用：编排、管理、调度用户提交的作业  Scheduler：编排和调度Pod，基本原理是通过监听api-server获取待调度的pod，然后基于一系列筛选和评优，为pod分配最佳的node节点。 APIServer：提供集群对外访问的API接口实现对集群资源的CRUD以及watch，是集群中各个组件数据交互和通信的枢纽，当收到一个创建pod的请求时会进行认证、限速、授权、准入机制等检查后，写入etcd。 Controller Manager：管理控制器的，比如Deployment、Job、CronbJob、RC、StatefulSet、Daemon等，核心思想是监听、比较资源实际状态与期望状态是否一致，否则进行协调。   Device Plugin：管理节点上的硬件设备，比如GPU Kube-Proxy：作为daemonset部署在每个节点上，主要用于为Pod创建代理服务，从API-Server获取所有service信息，创建Endpoints，转发service到Pod间的请求，默认使用iptables模式，但当service数量变多时有性能问题，1.8版本后使用IPVS模式提升性能 coreDNS：低版本的kubernetes使用kube-dns，1.12后默认使用coreDNS，用于实现域名查找功能  调度器Scheduler 主要职责就是为新创建的Pod寻找合适的节点，默认调度器会先调用一组叫Predicate的调度算法检查每个Node，再调用一组叫Priority的调度算法为上一步结果里的每个Node打分，将新创建的Pod调度到得分最高的Node上。
原理  
  第一个控制循环叫Informer Path，它会启动一系列Informer，监听etcd中的Pod、Node、Service等与调度相关的API对象的变化，将新创建的Pod添加进调度队列，默认的调度队列是优先级队列；
此外，还会对调度器缓存进行更新，因为需要尽最大可能将集群信息Cache化，以提高两个调度算法组的执行效率，调度器只有在操作Cache时，才会加锁。
  第二个控制循环叫Scheduling Path，是负责Pod调度的主循环，它会不断从调度队列里出队一个Pod，调用Predicate算法进行过滤，得到可用的Node，Predicate算法需要的Node信息，都是从Cache里直接拿到；</description>
    </item>
    
    <item>
      <title>MySQL</title>
      <link>http://nixum.cc/p/mysql/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mysql/</guid>
      <description>[TOC]
基础架构 MySQL逻辑架构图  
 连接器：负责跟客户端建立连接、获取权限、维持和管理连接。登录进去后修改权限，默认是将在下一次登录后生效 查询缓存：MySQL接收到查询请求后会先查询缓存，key是查询语句，value是查询结果，之后经过执行器的权限判断再返回，如果查不到则往后走。不建议使用，因为若有更新操作，会删除对应表的缓存，可能导致缓存命中低，可以设置query_cache_type=demand，默认不使用缓存，需要在查询时显示指定。MySQL8.0删除此功能 分析器：对SQL语句进行分析，词法分析判断各个字符串代表的含义（包括列是否存在），语法分析判断SQL的语法是否正确，这一层操作之后，MySQL就知道你要做什么了 优化器：决定是否要使用索引，使用哪个索引，决定表的连接顺序 执行器：先判断是否有对该表的操作权限，之后判断要使用哪个引擎提供的接口 引擎：对数据进行具体操作的执行者，事务和索引都是在这层做的，但具体需要引擎支持，例如MyISAM不支持事务，InnoDB支持  日志系统   redo log重做日志：InnoDB独有，物理日志，记录这个页做了什么改动，使用二阶段提交保证两份日志逻辑一致。记录写入到redo log后状态是prepare，binlog写入磁盘，事务提交，redo log改为commit状态，在写的时候是先写进redo log buffer，commit后才写进redo log(磁盘)
当有记录要更新的时候，InnoDB会先把记录(包含数据变更和change buffer的变更)写到redo log里，并更新内存，再在恰当的时候更到磁盘里，redo log prepare、commit 的XID对应bin log的XID实现关联。
InnoDB的redo log是固定大小的，比如有一组4个文件组成的“环形队列”，首位指针表示当前记录的位置和当前擦除位置，擦除前会把记录更新到磁盘，这种能力也称为crash-safe
建议设置innodb_flush_log_at_trx_commit=1，表示每次事务的redo log会持久化到磁盘
  bin log归档日志：属于server层的日志，逻辑日志，记录所有逻辑操作，追加写入，不会覆盖以前的日志，bin log有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，一般使用row，记录行变化前和变化后的数据，缺点是日志变大。从库是使用bin log进行备份的
建议设置sync_binlog=1，表示每次事务的bin log都会持久化到磁盘
  可以只使用redo log来实现崩溃恢复，但无法只使用bin log，原因是 InnoDB使用WAL机制（执行事务时，将操作记录写入内存和日志，事务就完成了，此时数据可能还没写入磁盘，MySQL会在合适的时机将内存里的数据刷入磁盘），如果此时数据库崩溃，要依赖日志来恢复数据页，但是bin log并没有记录数据页的更新细节，而redo log因为环形写入的问题，无法对所有记录进行归档，仅仅只能实现崩溃恢复
备份时间的长短会影响日志文件的大小，文件的完整性，从而影响到恢复速度和恢复效果
 undo log回滚日志：InnoDB独有，逻辑日志，主要用于事务失败时的回滚，以及MVCC中版本数据查看。当事务被提交后，并不会马上被删除，而是放到待清理链中，=到没有事务用到该版本信息时才可以清理。  参考：MySQL中的日志机制
常用SQL Count(*)、Count(1)、Count([列])区别 在count(*)不带条件在MyISAM里查询比较快，因为MyISAM会存储总条数，不带条件查询的时候直接用就行，而InnoDB带了事务，支持MVCC，因此每次count(*)时都会扫表
以下归纳基于InnoDB，count会返回满足条件的结果集的总行数，它会使用存储引擎进行全表扫描获取结果，比如count(1)会直接返回1，count(主键)会获取主键，返回给server层，由server层进行计数，因此按效率排序是：count(字段) &amp;lt; count( 主键id) &amp;lt; count(1) ≈ count(*)
 count（列）会计算列或这列的组合不为空的计数 count(*) 跟 count(1) 的结果一样，都包括对NULL的统计，而count([列名]) 是不包括NULL的统计 对于计数，也可以通过创建列为表名、total的表进行计数，利用事务能力，一般是先insert在update，理由是并发进行total值的更新时，是会上行锁的，如果先update total值可能会导致事务处理时间过长  having的使用   having一般需要搭配 group by 使用，在group by之后，order by之前</description>
    </item>
    
    <item>
      <title>网络</title>
      <link>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</guid>
      <description>[TOC]
从浏览器输入URL之后都发生了什么 浏览器输入URL，按回车，
 浏览器根据输入内容，匹配对应的URL和关键词，校验URL的合法性，补全URL，使其符合通用URI的语法。 请求发出前，如果当前的URL被访问过，会先进入缓存中查询是否有要请求的文件，有则直接返回；如果没有，则跳过缓存，进入网络操作。缓存会存在于路由缓存、DNS缓存、浏览器缓存、ServiceWorker、MemoryCache、DiskCache、PushCache、系统缓存等。 从URL中解析出域名，依次经过浏览器缓存、系统缓存、hosts 文件、路由器缓存、 递归搜索DNS服务器，找到对应的IP地址。 应用层程序准备好数据后，委托给操作系统，复制应用层数据到内核的内存空间中，交给网络协议栈（将其打包为tcp包(传输层)，帧(数据链路层)，并数据其从内核拷贝到网卡，后续由网卡负责数据的发送）建立 TCP/IP 连接（三次握手具体过程）。 HTTP 请求经过路由器的转发，通过服务器（CDN、反向代理之类的）的防火墙，该 HTTP 请求到达了服务器 服务器处理该 HTTP 请求，返回一个 HTML 文件 浏览器解析该 HTML 文件，解析HTML文件后，构建dom树 -》构建render树 -》布局render树 -》绘制 render树，自上而下加载，边加载边解析渲染，显示在浏览器端，对于图片音频等则是异步加载  本质上是OSI七层模型 + 相应协议、组件实现
HTTP方法 菜鸟HTTP教程/HTTP请求方法
Get和Post的区别   语义上的区别，Get一般表示查询、获取，Post是更新
  Get具有幂等性，Post没有
  参数传递方面，Get一般参数接在Url上，对外暴露，有长度限制（1024个字节即256个字符），只接收ASCII字符，需要进行url编码
Post参数放在request body里，支持多种编码
  GET请求会被浏览器主动cache，而POST不会，除非手动设置
  GET产生的URL地址可以加入书签，而POST不可以
  GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
  GET在浏览器回退时是无害的，而POST会再次提交请求
  其实本质都是一种协议的规范，规定参数的存放位置，参数长度大小等，当然也可以反着来，只要服务器能够理解即可
幂等性：同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的，每次返回的结果一样，不产生副作用；
根据语义，简单的把get看成查询，只要服务器的数据没变，每次查询得到的结果是一样的，而把post看成添加，每次post请求都会创建新资源，服务器状态改变
具有幂等性的方法：GET、HEAD、OPTIONS、DELETE、PUT
没有幂等性的方法：POST
安全性：安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。
常见状态码 参考HTTP状态码</description>
    </item>
    
    <item>
      <title>UML</title>
      <link>http://nixum.cc/p/uml/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/uml/</guid>
      <description>[TOC]
类图 类图中的关系其实有多种版本的表示方法，这里仅总结自己常用的画法
访问作用域   + : public
  - : private
  # : protocted
  关系 1. 依赖（dependency） 依赖关系是五种关系中耦合最小的一种关系。
依赖在代码中主要体现为类A的某个成员函数的返回值、形参、局部变量或静态方法的调用，则表示类A引用了类B。
A &amp;mdash;-&amp;gt; B ： A use B （虚线+箭头）
 A use B 
2. 关联（Association） 在程序代码中，具有关联关系的类常常被声明为类的引用类型的成员变量。
因为 关联 是 依赖 的更详细说明， 关联 是专门描述成员属性的关系，所以依赖中所有涉及成员属性的地方更适合使用：关联、聚合、组合
单向关联：
A ——————&amp;gt; B ： A has B （实心线 + 箭头）
 A has B 
3. 聚合（Aggregation） 聚合是关联的一种特殊形式，暗含整体/部分关系，但是对方却不是唯一属于自己的那种关系。 用来表示集体与个体之间的关联关系，例如班级与学生之间存在聚合关系。
A &amp;lt;&amp;gt;—————— B : A是集体，B是个体 （实线 + 空心菱形）</description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>http://nixum.cc/p/jvm/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/jvm/</guid>
      <description>[TOC]
JVM内存模型  JVM内存模型 
方法区也叫永久代，持久代，非堆，不算在堆里面
年轻代也叫新生代
注意区别于Java内存模型
JVM内存模型描述的是线程运行时的数据在内存的分布
Java内存模型是多线程情况下数据的分布
引用类型  强引用：通过new的方式创建，不会被轻易回收 软引用（SoftReference）：被软引用关联的对象只有在内存不够时才会被回收 弱引用（WeakReference）：被弱引用关联的对象一定会被回收，只能存活至下次垃圾回收发生之前 虚引用（PhantomReference）：比如将对象引用设置为null，该引用指向的对象就会被回收，相当于告知JVM可以回收该对象  软引用、弱引用、虚引用均可以搭配引用队列使用，且虚引用必须搭配引用队列使用。使用引用队列时，这些引用对象被垃圾收集器回收之后会进入引用队列，等待二次回收。引用队列一般用于与GC交互的场景，比如，垃圾回收时进行通知。
引用计数法 为对象添加一个引用计数器，当对象增加一个引用时，计数器加 1，引用失效时，计数器减 1。引用计数为 0 的对象可被回收。
比较轻便，效率较高，不需要STW，可以很快进行回收，但维护引用计数也有一定的成本
但有可能出现循环引用，JVM没有使用该判断算法，可能因为编译的时候并不会检测对象是否存在循环引用？go的话会在编译期检测是否存在循环引用，但是它垃圾回收使用三色标记法，本质是标记清除
可达性分析 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收，不可达指的是游离在GC Root外的对象。
GC Roots包括：
  java虚拟机栈中引用的对象
方法执行时，JVM会创建一个相应的栈帧进入java虚拟机栈，栈帧中包括操作数栈、局部变量表、运行时常量池的引用、方法内部产生的对象的引用，当方法执行结束后，栈帧出栈，方法内部产生的对象的引用就不存在了，此时这些对象就是不可达对象，因为无法从GC Roots找到，这些对象将在下次GC时回收。
比如，方法内部创建一个对象A，并持有另一个对象B，对象B引用也同时被其他线程持有，然后在方法里设置对象A=null或者方法结束后，个人认为对象A会被回收，对象B不会被回收，如果是方法外有一个对象C引用了对象A，设置对象A=null或方法结束后，对象A不会被回收
  方法区中类静态属性引用的对象、常量引用的对象
静态属性或者静态变量，是class的属性，不属于任何实例，该属性会作为GC Roots，只要该class存在，该引用指向的对象也会一直存在，只有该class被卸载时，才会被回收。对于常量池里的字面量，当没有其他地方引用这个字面量时，也会被清除。
  本地方法栈中Native方法引用的对象
这部分属于其他语言写的方法所使用到的对象，道理跟上面是java虚拟机栈是类似的
  上面两种更像是判断什么对象该被回收，至于要怎么回收，回收有什么策略，就有下面这几种了。
复制 标记-清理 标记 - 整理 三色标记   把所有对象放到白色的集合中 从根节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中 遍历灰色集合对象，把灰色对象引用的白色集合的对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色集合中 循环步骤3，直到灰色集合中没有对象 步骤4结束后，白色集合中的对象为不可达对象，进行回收   参考：深入理解Go-垃圾回收机制
垃圾收集器 CMS 执行过程   初始标记(STW initial mark)：这个过程从垃圾回收的&amp;quot;根对象&amp;quot;开始，只扫描到能够和&amp;quot;根对象&amp;quot;直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记(Concurrent marking)：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 并发预清理(Concurrent precleaning)：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段&amp;quot;重新标记&amp;quot;的工作，因为下一个阶段会Stop The World。 重新标记(STW remark)：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从&amp;quot;跟对象&amp;quot;开始向下追溯，并处理对象关联。 并发清理(Concurrent sweeping)：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。 并发重置(Concurrent reset)：这个阶段，重置CMS收集器的数据结构状态，等待下一次垃圾回收。   G1 执行过程   标记阶段：首先是初始标记(Initial-Mark),这个阶段也是停顿的(stop-the-word)，并且会稍带触发一次yong GC。 并发标记：这个过程在整个堆中进行，并且和应用程序并发运行。并发标记过程可能被yong GC中断。在并发标记阶段，如果发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，每个区域的对象活性(区域中存活对象的比例)被计算。 再标记：这个阶段是用来补充收集并发标记阶段产新的新垃圾。与之不同的是，G1中采用了更快的算法:SATB。 清理阶段：选择活性低的区域(同时考虑停顿时间)，等待下次yong GC一起收集，对应GC log: [GC pause (mixed)]，这个过程也会有停顿(STW)。 回收/完成：新的yong GC清理被计算好的区域。但是有一些区域还是可能存在垃圾对象，可能是这些区域中对象活性较高，回收不划算，也肯能是为了迎合用户设置的时间，不得不舍弃一些区域的收集。   内存分配和回收策略  1.</description>
    </item>
    
    <item>
      <title>Spring和SpringBoot</title>
      <link>http://nixum.cc/p/spring%E5%92%8Cspringboot/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/spring%E5%92%8Cspringboot/</guid>
      <description>[TOC]
SpringBoot Spring 和 Spring Boot区别 Spring Boot实现了自动配置，降低了项目搭建的复杂度。它主要是为了解决使用Spring框架需要进行大量的配置太麻烦的问题，所以它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，做到零配置即用。内置Tomcat作为Web服务器，不像之前还要把服务部署到Tomcat在进行启动。
SpringBoot整个启动流程  构建SpringApplication对象，执行其run方法 加载properties/yaml等配置文件 创建ApplicationContext（也可以称为Bean、IOC容器） 将扫描到的Bean或者xml中的bean，先解析成BeanDefinition，注册到ApplicationContext中的BeanFactory中（即自动配置过程，也是IOC容器的refresh方法执行过程） 实例化Bean，进行依赖注入，（AOP也是在此处实现，创建代理实例加入IOC容器）   SpringBoot启动流程 
参考SpringBoot启动流程解析
SpringBoot启动流程
SpringBoot自动配置流程 自动配置流程只是SpringBoot启动中的一个环节，该环节只是在告诉Spring要在哪里找到Bean的声明。
启动类main方法为入口，main方法所在的类会被**@SpringBootApplication**修饰， 通过main方法里执行**SpringApplication.run(Application.class, args)**进行启动，Spring启动时会解析出@SpringBootApplication注解，进行Bean的加载和注入。
  @SpringBootApplication里包含了
  @SpringBootConfiguration：作用类似于**@Configuration**，JavaConfig配置类，相当一个xml文件，配合@Bean注解让IOC容器管理声明的Bean
  @ComponentScan：配上包路径，用于扫描指定包及其子包下所有类，如扫描@Component、@Server、@Controller等，并注入到IOC容器中
  @EnableAutoConfiguration：自动配置的核心注解，主要用于找出所有自动配置类。该注解会使用**@Import(EnableAutoConfigurationImportSelector.class**)帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。
    EnableAutoConfigurationImportSelector类里有个SpringFactoriesLoader工厂加载器，通过里面的loadFactoryNames方法，传入工厂类名称和对应的类加载器，加载该类加载器搜索路径下的指定文件spring.factories文件，传入的工厂类为接口，而文件中对应的类则是接口的实现类，或最终作为实现类，得到这些类名集合后，通过反射获取这些类的类对象、构造方法，最终生成实例。
因此只要在maven中加入了所需依赖，根据spring.factories文件里的key-value，能够在类路径下找到对应的class文件，就会触发自动配置
  自定义starter 实际上就是编写自动配置类，会使用到一系列配置注解，如@Configuration、@EnableConfigurationProperties、@Component、@Bean、@ConditionOnXX、@AutoConfigureOrder等，让IOC容器加载我们自定义的Bean进去；
另外就是必须在META-INF文件夹下创建spring.factories，告知Spring在哪找到配置类。
org.springframework.boot.autoconfigure.EnableAutoConfiguration=[自定义配置类的全限定名称] 自定义Starter可以理解为一个Jar包，该Jar包在Maven或Gradle注册后，服务启动时，IOC容器会去自动加载。
自定义Starter内也可以使用配置文件，设定默认配置的key-value，当本项目里有配置的key与starter里定义的配置key重复时可以被替换
ContextLoaderListener 【Spring】浅谈ContextLoaderListener及其上下文与DispatcherServlet的区别
 作为Spring启动入口 实现了ServletContextListener 接口，监听ServletContext，如果 ServletContext 发生变化（如服务器启动时ServletContext 被创建，服务器关闭时 ServletContext 将要被销毁）时，执行监听器里的方法 为IOC容器提供环境，扫描包，将带有注解的Bean加入到容器用于依赖注入，或者加载xml文件，将xml注册的bean加入容器用于依赖注入  常用注解 @Controller与@RestController  @Controller 默认是返回视图，即方法的return返回的是视图层的路径，只有+@ResponseBody才会返回Json格式的数据 @RestController实际上是@Controller + @ResponseBody组合，默认返回json格式的数据  @Autowired与@Resource   @Autowired 注解，修饰类成员变量、方法及构造方法，完成自动装配的工作，默认按 byType 自动注入。只有一个required属性，默认是true，表示必须注入，不能为null</description>
    </item>
    
    <item>
      <title>Java并发</title>
      <link>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</guid>
      <description>[TOC]
线程、进程、协程   进程：可以简单理解为一个应用程序，进程是资源分配的基本单位。比如一个进程拥有自己的堆、栈、虚存空间、文件描述符等。
涉及到用户态和内核态的切换。
进程间的通信：
 匿名管道：半双工，数据只能向一个方向流动，双方需要通信时，需要建立起两个管道；且只能用于有亲缘关系的进程；本质是一个内核缓冲区，可以看成是内存中的文件，但不属于某种文件系统，无需显示打开，创建时直接返回文件描述符，读写时需要确定对方的存在，否则将退出；以先进先出的方式存取数据，通信的双方需制定好数据的格式； 有名管道：主要解决匿名管道只能作用与有亲缘关系的进程的问题，通过一个路径名关联，以文件形式存在于文件系统中，即使没有亲缘关系的进程也能通过访问路径实现通信；管道名字存在于文件系统中，内容存在内存中；打开时就得确定对方是否存在，否则将阻塞； 信号：操作系统提供的一种机制，可以在任何时候发给某一进程，而无需指定该进程的状态，如果该进程当前处于未执行状态，该信号就由内核保存起来，直到进程回复执行并传递为止；信号接收可以被阻塞，直到阻塞解除；本质是对中断机制的模拟，异步通信，在用户态和内核态之间交互；能携带的信息较少。 消息队列：存放在内核中的消息链表，只有在内核重启或显示地删除时，才会被真正的删除，与管道不同的是消息队列不需要确定接收进程是否存在；一般是FIFO，但也可以实现成随机查询；对消息格式，缓冲区大小等都能进行控制，比管道灵活； 共享内存：没什么好说的，只是在访问共享内存时要依靠一些同步或互斥机制保证并发访问安全； 信号量：计数器，一般用于多进程对共享内存访问的保护，内核中实现，保证原子操作 套接字：通信机制，可用在本机或者跨网络，由域、端口号、协议类型三个属性确定；域分为AF_INET，即网络，另一个是AF_UNIX，即文件系统    线程：线程是独立调度的基本单位，由CPU进行调度和执行的实体。一个进程中可以有多个线程，线程之间共享进程资源，是进程中的实际运作单位。
涉及到用户态和内核态的切换。
  协程：GoLang中的协程
 在用户态层面，由线程控制，即用户应用层面自己控制，很难像抢占式调度那样强制CPU切换到其他线程/进程，只能是协作式调度，但同时也避免了上下文切换 内存消耗比线程小，比如go开启协程是几kb，java开启一个线程至少1MB 实现原理：在一个运行的线程上，起多个协程，每个协程会加入到调度队列中，线程会从调度队列里取出协程进行运行。队列个数默认取决于CPU的个数，协程间的切换会线程使用go提供的io函数进行控制。当有协程执行较慢时，会先将其挂起，然后唤醒其他线程，将未处理的协程队列转移到该线程，消费队列里的协程，当队列消费完成后，再切回原来的线程，继续执行刚刚挂起的协程。    参考：图解Go协程调度原理，小白都能理解 
Golang 的 goroutine 是如何实现的？
进程与线程的区别   拥有资源
进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
  调度
线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
  系统开销
由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
  通信方面
线程间可以通过直接读写同一进程中的数据进行通信，在java中如使用共享变量、wait/notify机制、阻塞队列；但是进程通信需要借助管道、消息队列、共享存储、信号量、信号、套接字socket
  上下文切换的开销
当CPU从执行一个线程切换到执行另外一个线程的时候，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。这种切换称为“上下文切换”(“context switch”)。CPU会在一个上下文中执行一个线程，然后切换到另外一个上下文中执行另外一个线程。
调度方式  非抢占式：系统一旦开始执行某一进程，就会让该线程就会一直执行下去，直至完成，或者发生了其他事件导致系统放弃对该进程的执行后，才会去执行另外一个进程。 抢占式：系统执行某一进程，在其执行期间，系统可以立即停止当前进程，转而执行另外一个进程，待处理完后，重新回来继续执行之前停止的进程  调度原理 用户空间线程和内核空间线程之间的映射关系</description>
    </item>
    
    <item>
      <title>git</title>
      <link>http://nixum.cc/p/git/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/git/</guid>
      <description>git流程 
常用命令   git init
将一个普通文件夹变成git仓库，此时文件夹下多出.git文件夹，表示可以使用git管理，此时这个文件夹称为git工作区
或者
使用git clone url(github上的仓库链接)将仓库从github上下载下来
  当对工作区内的文件做出修改后   git add 文件名
表示将该文件的修改加入到暂存区
  git add .
(注意后面有个 . )表示将当前目录下的所有文件的修改都加入到暂存区
  git commit -m &amp;ldquo;备注信息&amp;rdquo;
表示将暂存区的修改提交到当前分支，提交之后暂存区清空
  git push -u origin master
将分支上的修改更新到github上
  撤回修改   git log 查看提交记录，获取commit id
  git reset &amp;ndash; 文件名 或者 commitId
使用当前分支上的修改覆盖暂存区，用来撤销最后一次 git add files
  git checkout &amp;ndash; 文件名</description>
    </item>
    
    <item>
      <title>Java List Map</title>
      <link>http://nixum.cc/p/java-list-map/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-list-map/</guid>
      <description>[TOC]
以下笔记如没指定版本，都是基于JDK1.8
Collection  javaCollection类图简版 
Set HashSet 1.基本   底层是HashMap，因此初始容量，默认负载因子、扩容倍数这些都和HashMap一样
  由于HashSet只需要key，因此value统一使用静态不可变的Object对象来装，即所有key共享这一个对象
  private transient HashMap&amp;lt;E,Object&amp;gt; map; private static final Object PRESENT = new Object();  HashSet允许存入null 不是线程安全的 不保证插入元素的顺序  List ArrayList 1.基本   底层：Object数组
  默认大小：10 （调用空参构造方法时）
最大是Integer.MAX_VALUE - 8（2^31 - 1，一些虚拟器需要在数组前加个头标签，所以减去 8 ）
调用此构造方法时，
public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) 其中要注意的是，里面有这样一句话
// c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].</description>
    </item>
    
    <item>
      <title>Java SE</title>
      <link>http://nixum.cc/p/java-se/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-se/</guid>
      <description>[TOC]
一、面向对象 面向对象的特征： 抽象(注意与当前目标有关的，选择一部分，暂时不用部分细节，分为过程抽象、数据抽象) 继承：联结类的层次模型、允许和鼓励类的重用，派生类可以从它的基类那里继承方法和实例变量，进行修改和新增使其更适合 封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面，这些对象通过一个受保护的接口访问其他对象 多态：允许不同类的对象对同一消息作出响应，包括参数化多态性和包含多态性，灵活、抽象、行为共享、代码共享，解决程序函数同名问题
二、基础类型及其包装类型    基本类型 boolean byte char short int float long double     包装类型 Boolean Byte Character Short Integer Float Long Double   位数 1 8 16 16 32 32 64 64   字节数  1 2 2 4 4 8 8      字符集
unicode是字符集，一种标准，UTF-8、UTF-16、GBK之类的是编码方式，是字符集的具体实现
UTF-16：定长,固定2字节， UTF-8：变长,中文占3字节,英文占1字节
char可以保存一个中文字符
java中采用unicode编码，无论中文、英文都是占2个字节
java虚拟机中使用UTF-16编码方式
java的字节码文件(.class)文件采用的是UTF-8编码，但是在java 运行时会使用UTF-16编码。
参考Java中的UTF-8、UTF-16编码字符所占字节数</description>
    </item>
    
    <item>
      <title>SpringMVC</title>
      <link>http://nixum.cc/p/springmvc/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/springmvc/</guid>
      <description>SpringMVC工作原理 SpringMVC工作原理详解
流程图看链接里的即可
简单来说各个组件的作用
 前端控制器DispatcherServlet：请求的入口，可以看成是中央处理器、转发器，负责调度其他组件，接收请求，完成响应 处理器映射器HandlerMapping：根据请求的url查找Handler，找到url对应的controller类，返回一条执行链，其中就包含拦截器和处理器（具体的controller类）；有配置文件方式，实现接口方式，注解方式等方式实现映射 处理器适配器HandlerAdapter：HandlerMapping找到对应的controller类后，再根据url找到对应的执行方法 处理器Handler：具体的处理方法，也就是我们所写具体的Controller类 视图解析器View resolver：根据逻辑View名称，找到对应的View，根据处理器返回的ModelAndView，将数据渲染到View上 视图View：例如jsp，freemarker之类的视图模板  拦截器在什么时候执行？
拦截器，是属于HandlerMapping级别的，可以有多个HandlerMapping ，每个HandlerMapping可以有自己的拦截器，拦截器可以设置优先级。一个请求交给一个HandlerMapping时，这个HandlerMapping先找有没有处理器来处理这个请求，如何找到了，就执行拦截器，执行完拦截后，交给目标处理器。如果没有找到处理器，那么这个拦截器就不会被执行。
实现HandlerInterceptor接口或者继承HandlerInterceptor，重写boolean preHandle()、void postHandle()、void afterCompletion()方法
  preHandle() 方法：该方法会在控制器方法前执行，其返回值表示是否中断后续操作。
当其返回值为true时，表示继续向下执行；当其返回值为false时，会中断后续的所有操作（包括调用下一个拦截器和控制器类中的方法执行等）。
  postHandle()方法：该方法会在控制器方法调用之后，且解析视图之前执行。可以通过此方法对请求域中的模型和视图做出进一步的修改。
  afterCompletion()方法：该方法会在整个请求完成，即视图渲染结束之后执行。可以通过此方法实现一些资源清理、记录日志信息等工作。
  Spring Security 简单工作流程
请求(包含用户名，密码之类)——&amp;gt;登陆信息封装成一个Authentication对象——&amp;gt;AuthenticationManager，调用authenticate ()方法处理——&amp;gt;该方法会将对象传递给一系列AuthenticationAdapter（一系列Filter），每一个AuthenticationAdapter会调用它们配置的UserDetailsService处理</description>
    </item>
    
    <item>
      <title>MyBatis</title>
      <link>http://nixum.cc/p/mybatis/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mybatis/</guid>
      <description>[TOC]
ORM 普通JDBC使用sql的prepareStatement + sql + 占位符 + 参数的方式执行sql语句
ORM其实就是在先编写类与数据库表字段的映射，可以是xml配置，也可以是注解配置，之后再使用JDBC执行sql时，通过对类的反射获得其属性的值和对应的字段名，拼接sql+占位符+属性值，执行sql语句
MyBatis #{}和${}区别
#{}：预编译，底层是PrepareStatement ，可防止SQL注入
${}：参数替换，不能防止SQL注入
dao接口与mapper的映射  通过动态代理实现 实际上XML在定义Mapper的时候就相当于在编写dao类了，dao接口类相当于编写调用入口 XML中的配置信息会被存放在Configuration类中，SqlSessionFactoryBuilder会读取Configuration类中的信息创建SqlSessionFactory，之后由SqlSessionFactory创建sqlSession 在启动时先扫描并加载所有定义Mapper的XML，解析XML，根据XML中的namespace找到对应的接口，为这些接口生成对应的代理工厂MapperProxyFactory。 sqlSession.getMapper时，会通过传入的类/接口名（即被代理类）找到对应的MapperProxyFactory，生成代理类MapperProxy，并注入sqlSession，MapperProxy实现InvocationHandler接口进行代理，通过MapperMethod执行SQL，MapperMethod使用注入的sqlSession和解析XML中配置的SQL语句得到的参数，调用对应的executor执行SQL  缓存  一级缓存的作用域是同一个SqlSession，在同一个sqlSession中两次执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。当一个sqlSession结束后该sqlSession中的一级缓存也就不存在了。Mybatis默认开启一级缓存。 二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession去操作数据库得到数据会存在二级缓存区域，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。不同的sqlSession两次执行相同namespace下的sql语句且向sql中传递参数也相同即最终执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。Mybatis默认没有开启二级缓存需要在setting全局参数中配置开启二级缓存  参考 MyBatis的通俗理解：SqlSession.getMapper()源码分析</description>
    </item>
    
    <item>
      <title>README</title>
      <link>http://nixum.cc/p/readme/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/readme/</guid>
      <description>&lt;h1 id=&#34;content&#34;&gt;Content&lt;/h1&gt;
&lt;p&gt;个人是后端开发，以Go和Java为主要开发语言，该Repository主要记录已使用或者感兴趣的技术的知识点，以及一些工作中的感受之类。&lt;/p&gt;
&lt;p&gt;emmm有时间再好好美化首页README。&lt;/p&gt;
&lt;p&gt;阅读的时候可以直接看对应的gitbook即可，&lt;a class=&#34;link&#34; href=&#34;https://nixum.gitbook.io/note&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;gitbook入口&lt;/a&gt;、&lt;a class=&#34;link&#34; href=&#34;https://github.com/Nixum/Note&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github入口&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
