<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据库 on Nixum Blog</title>
    <link>http://nixum.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
    <description>Recent content in 数据库 on Nixum Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="http://nixum.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MongoDB</title>
      <link>http://nixum.cc/p/mongodb/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mongodb/</guid>
      <description>[TOC]
特点  分布式数据库，Json数据模型，面向对象数据模型，不强制表的scheme 当应用场景不清晰时，可以直接以对象模型直接存储，无需关心字段，表结构灵活，动态增加新字段 不用太过关注表间的关系，可直接嵌套存储，将多种关系存储在同一张表上，同时也加快查表，因为它可以减少磁盘定位次数，如果是关系型数据库，同时查多张表就需要定位多次 原生支持高可用，一般的部署方式是部署三个节点replica set，最多50个；多replica set可以实现自恢复（当主节点挂点后会选出从节点），异地容灾，数据库滚动更新 原生支持横向扩展，通过水平扩展分片实现，外部并不感知有多少个分片，只会当成一个分片使用 支持字段级加密，针对隐私数据，比如身份证、电话等，在入库时可以进行加密，查询时解密 支持地理位置经纬度查询 强大的聚合查询，适合报表、时序数据  NoSQL语句 客户端使用驱动时连接的执行流程
 客户端执行流程 
数据库端执行流程
 数据库端执行流程 
要获取ticket是因为MongoDB默认存储引擎wiredtiger的机制，ticket代表着系统资源的数量，ticket数量有限，读写操作都需要先获得ticket才可以进行下一步操作，机制类似信号量。
连接 连接mongoDB语句，当有多节点或多分片时，连接也要写上，mongodb://节点1的host:port, 节点2的host:port,.../databaseName?[options: maxPoolSize(java默认是100), maxWaitTime(查询的最大等待事件), writeConcern, readConcern]
mongoDB驱动里已提供负载均衡，多节点探测
聚合 作用相当与group by，可作用与多个collection，可进行查询和计算。Mongo的聚合操作发生在pipeline中，由多个stage组成，有点像责任链，通过多个state来过滤，聚合数据，每一个{}代表一个state
demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  MySQL中的SELECTdepartment,count(null)asemp_QTYFROMUserWHEREgender=&amp;#39;female&amp;#39;GROUPBYdepartmentHAVINGcount(*)&amp;lt;10等价于mongo中的db.user.aggregate([{$match:{gender:&amp;#39;female&amp;#39;}},{$group:{_id:&amp;#39;$DEPARTMENT&amp;#39;,emp_qty:{$sum:1}}},{$match:{emp_qty:{$lt:10}}}])  几个比较特别的运算符
$unwind：将查询到的数组展开
$grouphLookup：图搜索
$facet/$bucket：分面搜索，根据不同范围条件，多个维度一次性进行分组输出
文档模型设计原则   传统关系型数据库设计，从概念模型 -》逻辑模型 -》物理模型，关系明确，遵循三范式（1.要有主键，列不可分，2.每列与主键相关，3.不能存在传递依赖(不允许字段冗余)），表现形式上，一对多关系，外键在多那张表上，多对多关系，会有第三张表来做关联
对于文档模型，一般对应关系型数据库设计的逻辑模型阶段，通过嵌套实体数组，map或者引用字段来处理实体间的关系，字段冗余限制宽松
  实体间的关系，一对一使用嵌套map来表示；一对多使用嵌套数组表示；多对多使用嵌套数组+冗余字段来表示；此外，也可以通过嵌套数组存id + 另一张表来表示实体间的关系，通过id来进行联表（使用aggregate + $lookup）</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>http://nixum.cc/p/redis/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/redis/</guid>
      <description>[TOC]
数据类型及结构 数据类型 具体的分为5种基本类型和3种特殊类型：
String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet
 String：简单动态字符串(SDS) List：压缩列表（元素数量小于512，且所有元素的长度都小于64字节） + 双向链表（其他情况使用） Hash：压缩列表（元素数量小于512，且key和value字符串长度都小于64字节） + 哈希表（其他情况使用） Set：数组（带有编码类型字段，所以元素可以使用整型表示，少于512个时使用）+ 哈希表（key为set中的元素，value为null，其他情况使用） ZSet：压缩列表（元素小于128个，且所有元素的长度小于64字节时使用） + 跳表 （其他情况使用）  另外三种扩展类型：
 Bitmap：位存储，基于String，原理：String类型会保存二进制字节数组，只有0和1两个值，对于这个字节数组的每个bit来表示一个元素的二值状态； HyperLogLog：基数统计，类似set，主要作用是使用少量固定的内存（12KB内存即可统计2^64个不同元素）去存储并识别有大量元素的集合中的唯一元素，能快速算出集合内的元素个数，误差率0.81%；版本2.8.9之后才有 Geo：推算地理位置，比如两地之间的距离，方圆几里的人；版本3.2之后才有 Stream：5.0之后的版本才有，Stream会在第一次使用 xadd 指令追加消息时自动创建。  Consumer Group：消费组，一个消费组有多个消费者，这些消费者是竞争关系； Last_delivered_id：游标，每个消费组的游标，组内任意一个消费者读取了消息都会使游标向前移动； pending_ids：消费者的状态变量，用于维护消费者未确认的id，记录当前已经被客户端读取但还没有被ACK的消息。如果客户端没有ACK，这个变量里面的消息ID会越来越多，一旦某个消息被ACK，它就开始减少，用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。 消息ID：组成方式毫秒级时间戳 - 序号，消息ID也可以自定义，但必须是整数-整数，且能后面加入的消息ID要大于前面的消息ID。Redis本身会记录 lastest_generated_id，防止时间回拨导致ID问题； 消息内容：键值对，类似Hash的结构；     
底层数据结构 Redis所有类型有一个顶层的数据结构叫RedisObject，这个RedisObject底层对应着具体对象类型和其编码方式。
之所以有RedisObject对象，是因为每种不同的数据类型有不同的编码方式和结构，Redis必须让每个键都带有类型信息，使得程序可以检查键的类型，还需要根据数据类型的不同编码进行多态处理。
比如：SADD命令只能用于Set，LPUSH命令只能用于List，而DEL、TTL又能用于所有键，要正确实现这些命令，就需要为不同类型的键设置不同的处理方式；另外，同一种数据类型可能由不同的数据结构实现，比如List，底层可能是压缩列表或者双向链表，因此还需要知道数据类型的编码方式。
1 2 3 4 5 6 7 8 9 10 11 12 13  typedef struct redisObject { // 类型，如String、List  unsigned type:4; // 编码方式：SDS、压缩列表  unsigned encoding:4; // LRU - 24位, 记录最后一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间）  unsigned lru:LRU_BITS; // LRU_BITS: 24  // 引用计数，新创建对象时值为1，当对该对象进行共享时值+1，使用完一个对象后值-1，=0时被GC回收  int refcount; // 指向底层数据结构实例，具体的实例，由type和encoding决定  void *ptr; } robj;    当执行一个处理数据类型命令的时候，redis执行以下步骤</description>
    </item>
    
    <item>
      <title>MySQL</title>
      <link>http://nixum.cc/p/mysql/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mysql/</guid>
      <description>[TOC]
基础架构 MySQL逻辑架构图  
 连接器：负责跟客户端建立连接、获取权限、维持和管理连接。登录进去后修改权限，默认是将在下一次登录后生效 查询缓存：MySQL接收到查询请求后会先查询缓存，key是查询语句，value是查询结果，之后经过执行器的权限判断再返回，如果查不到则往后走。不建议使用，因为若有更新操作，会删除对应表的缓存，可能导致缓存命中低，可以设置query_cache_type=demand，默认不使用缓存，需要在查询时显示指定。MySQL8.0删除此功能 分析器：对SQL语句进行分析，词法分析判断各个字符串代表的含义（包括列是否存在），语法分析判断SQL的语法是否正确，这一层操作之后，MySQL就知道你要做什么了 优化器：决定是否要使用索引，使用哪个索引，决定表的连接顺序 执行器：先判断是否有对该表的操作权限，之后判断要使用哪个引擎提供的接口 引擎：对数据进行具体操作的执行者，事务和索引都是在这层做的，但具体需要引擎支持，例如MyISAM不支持事务，InnoDB支持  日志系统 关于物理日志和逻辑日志：物理日志记录每一个page具体存储的值，在这个数据页上做了什么修改，比如redo log；而逻辑日志记录每一个page中数据的变动过程，比如undo log、bin log、relay log；
比如一个page页中一个数据从 1 改到 2 ，再改到 3，物理日志记录最后一个值是 3 ，逻辑日志记录 1 -&amp;gt; 2, 2-&amp;gt;3 的过程。
  redo log重做日志：InnoDB独有，物理日志，记录这个页做了什么改动，使用二阶段提交保证两份日志逻辑一致。当有日志要写入时，先写到redo log buffer后状态是prepare，开始写bin log cache，bin log 写完后，事务提交，redo log 改为commit状态，redo log写完，此时事务就算完成；这里描述的写redo log和bin log都只写在了缓冲区，何时写进磁盘，是根据innodb_flush_log_at_trx_commit和sync_binlog配置决定。用于实现数据持久化，以及宕机恢复数据。
redo log 本质上记录了对某个表空间的某个数据页的某个偏移量修改了哪几个字节的值，具体修改的值是什么，一条redo log也就几个字节到十几个字节，格式是 日志类型，表空间ID，数据页号，数据页偏移量，具体修改的数据。redo log buffer默认是16MB，redo log 数据内容是记在 redo log block 里的，写满一个就存到redo log buffer里，然后写下一个，直到 buffer 满了，此时会强制刷盘。
redo log 是固定大小的，比如有一组4个文件组成的“环形队列”，环形写入，一个文件写完就写下一个，4个轮转，作用是redo log刷盘完成之后这部分内存就能重新利用；首位指针表示当前记录的位置和当前擦除位置。当前擦除位置是一个叫 LSN（log sequence number）的检查点，表示在LSN之前的数据（缓冲池里的数据页、索引页）都已经持久化到磁盘了，redo log文件里在LSN检查点之前的内容才允许被覆盖，擦除或覆盖之前一定会刷到磁盘。</description>
    </item>
    
  </channel>
</rss>
